/*
 * Globus device code:          Copyright 2005 Northern Illinois University
 * Borrowed MPICH-G2 code:      Copyright 2000 Argonne National Laboratory and Northern Illinois University
 * Borrowed MPICH2 device code: Copyright 2001 Argonne National Laboratory
 *
 * XXX: INSERT POINTER TO OFFICIAL COPYRIGHT TEXT
 */

#include "mpidimpl.h"
#if defined(HAVE_UNISTD_H)
#include <unistd.h>
#endif

mpig_process_t mpig_process = {NULL, "(unknown)", -1, -1, -1, -1};


/* FIXME: the defintion of this array should be generated by configure based on a list of communication modules. */
MPIG_STATIC const mpig_cm_vtable_t * const mpig_cm_vtables_array[] =
{
    &mpig_cm_self_vtable,
    &mpig_cm_vmpi_vtable,
    &mpig_cm_xio_vtable,
    &mpig_cm_other_vtable,
    NULL
};

const mpig_cm_vtable_t * const * const mpig_cm_vtables = mpig_cm_vtables_array;
const int mpig_cm_vtables_num_entries = sizeof(mpig_cm_vtables_array) / sizeof(mpig_cm_vtable_t *) - 1;


/*
 * MPID_Init()
 */
#undef FUNCNAME
#define FUNCNAME MPID_Init
int MPID_Init(int * argc, char *** argv, int requested, int * provided, int * has_args, int * has_env)
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    mpig_bc_t bc;
    mpig_bc_t * bcs = NULL;
    mpig_pg_t * pg = NULL;
    const char * pg_id = NULL;
    char * lan_id = NULL;
    bool_t pg_locked = FALSE;
    int pg_rank;
    int pg_size;
    MPID_Comm * comm;
    int n;
    globus_result_t grc;
    bool_t failed;
    int mpi_errno = MPI_SUCCESS;
    MPIG_STATE_DECL(MPID_STATE_MPID_INIT);

    MPIG_UNUSED_VAR(fcname);

    MPIG_FUNC_ENTER(MPID_STATE_MPID_INIT);
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "entering: requested=%d", requested));
    
    /* initialize the device's process information structure */
    mpig_process_mutex_create();
    mpig_process_rc_acq(FALSE);
    {
	/* get the operating system's process id for the local process */
	mpig_process.my_pid = getpid();

	/* get the name of the machine on which the local process is running */
#       if defined(HAVE_GETHOSTNAME)
	{
	    if(gethostname(mpig_process.my_hostname, (size_t) MPIG_PROCESSOR_NAME_SIZE) != 0)
	    {
		mpig_process.my_hostname[0] = '\0';
	    }
	}
#       else
	{
	    mpig_process.my_hostname[0] = '\0';
	}
#       endif
    }
    mpig_process_rc_rel(TRUE);
    
    /* set the maximum size of a message tag.  a communication module may reduce this value if needed. */
    MPIR_Process.attrs.tag_ub = INT_MAX;

    /* activate globus modules */
    globus_module_set_args(argc, argv);
    
    grc = globus_module_activate(GLOBUS_COMMON_MODULE);
    MPIU_ERR_CHKANDJUMP2((grc), mpi_errno, MPI_ERR_OTHER, "**globus|module_activate", "**globus|module_activate %s %s", "common",
	globus_error_print_chain(globus_error_peek(grc)));

    /* initialize the request allocator module */
    mpig_request_alloc_init();
    
    /* initialize the receive queue */
    mpi_errno = mpig_recvq_init();
    MPIU_ERR_CHKANDJUMP((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**globus|recvq_init");
    
    /* initialize the process management module which interfaces with globus */
    mpi_errno = mpig_pm_init();
    MPIU_ERR_CHKANDJUMP((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**globus|pm_init");

    /* initialize the process group tracking subsystem */
    mpi_errno = mpig_pg_init();
    MPIU_ERR_CHKANDJUMP((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**dev|pg_init");

    /* initialize the communication modules */
    for (n = 0; n < mpig_cm_vtables_num_entries; n++)
    {
	mpig_cm_vtables[n]->init(argc, argv, &mpi_errno, &failed);
	MPIU_ERR_CHKANDJUMP1((failed), mpi_errno, MPI_ERR_OTHER, "**globus|cm_init", "**globus|cm_init %s",
	    mpig_cm_vtables[n]->name);
    }

    /* create and populate the buiness card with contact information from the communication modules */
    mpig_bc_construct(&bc);

    for (n = 0; n < mpig_cm_vtables_num_entries; n++)
    {
	if (mpig_cm_vtables[n]->add_contact_info != NULL)
	{
	    mpig_cm_vtables[n]->add_contact_info(&bc, &mpi_errno, &failed);
	    MPIU_ERR_CHKANDJUMP1((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**globus|cm_add_contact", "**globus|cm_add_contact %s",
		mpig_cm_vtables[n]->name);
	}
    }

    /* add the LAN identification string to the business card (if one is defined) */
    lan_id = globus_libc_getenv("GLOBUS_LAN_ID");
    if (lan_id != NULL)
    {
	mpig_bc_add_contact(&bc, "GLOBUS_LAN_ID", lan_id, &mpi_errno, &failed);
	MPIU_ERR_CHKANDJUMP1((failed), mpi_errno, MPI_ERR_OTHER, "**globus|bc_add_contact",
	"**globus|bc_add_contact %s", "CM_XIO_LAN_ID");
    }
    
    /* use the process management module to exchange the businesses cards and obtian information about the process group. */
    mpi_errno = mpig_pm_exchange_business_cards(&bc, &bcs);
    MPIU_ERR_CHKANDJUMP((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**globus|pm_xchg");

    mpig_pm_get_pg_id(&pg_id);
    mpig_pm_get_pg_size(&pg_size);
    mpig_pm_get_pg_rank(&pg_rank);
    mpig_pm_get_app_num(&bcs[pg_rank], &MPIR_Process.attrs.appnum);

    /* place a copy of the process group information in the process structure */
    mpig_process.my_pg_id = MPIU_Strdup(pg_id);
    mpig_process.my_pg_size = pg_size;
    mpig_process.my_pg_rank = pg_rank;
    
    /* now that we know the process group rank, initialize the debugging output module */
#   if defined(MPIG_DEBUG)
    {
	mpig_debug_init();
    }
#   endif

    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_ADI3, "pid=%lu", (unsigned long) mpig_process.my_pid));
    
    /* acquire, creating if necessary, a reference to the process group object used to manage the virtual connection objects.  if
       creation was necessary, the virtual connection objects within the PG will be initialized at this time. */
    mpi_errno = mpig_pg_acquire_ref_locked(pg_id, pg_size, &pg);
    MPIU_ERR_CHKANDJUMP((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**globus|pg_acquire_ref");
    pg_locked = TRUE;
    {    
	mpig_vc_t * vc;
	bool_t vc_was_in_use;
	int p;

	/* stash away a pointer to my process group.  the PG reference count was already incremented by
	   mpig_pg_acquire_ref_and_lock().  it should be reduced again in MPID_Finalize() using mpig_pg_release(). */
	mpig_process.my_pg = pg;
	
	for (p = 0; p < pg_size; p++)
	{
	    bool_t selected;
	    bool_t found;

#	    if (FALSE)
	    {
		MPIG_DEBUG_STMT(MPIG_DEBUG_LEVEL_BC,
		{
		    char * bc_str;
		    mpig_bc_serialize_object(&bcs[p], &bc_str, &mpi_errno, &failed);
		    mpig_debug_uprintf(MPIG_DEBUG_LEVEL_BC, "serialized BC for process %s:%d - %s\n", pg_id, p, bc_str);
		    mpig_bc_free_serialized_object(bc_str);
		});
	    }
#	    endif

	    mpig_pg_get_vc(pg, p, &vc);

	    mpig_vc_mutex_lock(vc);
	    {
		/* stash a copy of the business card in the VC.  it will be used during the extraction of contact information,
		   and also by the MPI-2 dynamic process routines when an exchange of business cards is necessary. */
		mpig_bc_copy(&bcs[p], mpig_vc_get_bc(vc), &mpi_errno, &failed);
		MPIU_ERR_CHKANDJUMP((failed), mpi_errno, MPI_ERR_OTHER, "**globus|gc_copy");

		/* extract the contact information from the business card attached to the VC object.  the information is
		   extracted from the business card because it is used each time a communicator is created to construct the
		   topology information.  since the gathering of data from the business card is not necessarily efficient, the
		   information is extract to once and store in a form more easily manipulated by the machine. */
		for (n = 0; n < mpig_cm_vtables_num_entries; n++)
		{
		    if (mpig_cm_vtables[n]->extract_contact_info != NULL)
		    {
			mpig_cm_vtables[n]->extract_contact_info(vc, &mpi_errno, &failed);
			MPIU_ERR_CHKANDSTMT1((failed), mpi_errno, MPI_ERR_OTHER, {goto vc_unlock;},
			    "**globus|cm_extract_contact", "**globus|cm_extract_contact %s", mpig_cm_vtables[n]->name);
		    }
		}

		/*
		 * select the protocol that will be used for each VC
		 *
		 * NOTE: since no barrier exists in the process management interface, some communication modules could be
		 * susceptible to receiving connection requests from remote processes before the VCs have been initialized.  for
		 * such communication modules, the cm->select_module() routine must take care not to blindly reinitialize
		 * internal fields of the VC, causing the existing connection to be corrupted or lost.
		 */
		for (n = 0; n < mpig_cm_vtables_num_entries; n++)
		{
		    if (mpig_cm_vtables[n]->select_module != NULL)
		    {
			mpig_cm_vtables[n]->select_module(vc, &selected, &mpi_errno, &failed);
			MPIU_ERR_CHKANDSTMT3((failed), mpi_errno, MPI_ERR_OTHER, {goto vc_unlock;}, "**globus|cm_select_module",
			    "**globus|cm_select_module %s %s %d", mpig_cm_vtables[n]->name, pg_id, pg_rank);
			if (selected) break;
		    }
		}

		MPIU_ERR_CHKANDSTMT2((!selected), mpi_errno, MPI_ERR_OTHER, {goto vc_unlock;}, "**globus|cm_no_module",
				     "**globus|cm_no_module %s %d", pg_id, pg_rank);

		/* get the LAN indentification string, if one is present, and store it in the VC */
		mpig_bc_get_contact(&bcs[p], "GLOBUS_LAN_ID", &lan_id, &found, &mpi_errno, &failed);
		MPIU_ERR_CHKANDSTMT1((failed), mpi_errno, MPI_ERR_OTHER, {goto vc_unlock;}, "**globus|bc_get_contact",
		    "**globus|bc_get_contact %s", "GLOBUS_LAN_ID");
		if (found)
		{
		    vc->ci.lan_id = MPIU_Strdup(lan_id);
		    mpig_bc_free_contact(lan_id);
		    MPIU_ERR_CHKANDSTMT1((vc->ci.lan_id == NULL), mpi_errno, MPI_ERR_OTHER, {goto vc_unlock;}, "**nomem",
			"**nomem %s", "LAN ID");
		}

		/* get the app num from the business card and store it in the VC */
		mpi_errno = mpig_pm_get_app_num(&bcs[p], &vc->ci.app_num);
	        MPIU_ERR_CHKANDSTMT((mpi_errno), mpi_errno, MPI_ERR_OTHER, {goto vc_unlock;}, "**globus|pm_get_app_num");
		    
	      vc_unlock: ;
	    }
	    mpig_vc_mutex_unlock(vc);

	    if (mpi_errno) goto fn_fail;
	}

	/* free the business card array provided by the process management subsystem */
	mpig_pm_free_business_cards(bcs);
	
	/* initialize the topology information module */
	mpi_errno = mpig_topology_init();
	MPIU_ERR_CHKANDJUMP((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**globus|topology_init");
	
	/* initialize the MPI_COMM_WORLD object */
	comm = MPIR_Process.comm_world;

	comm->rank = pg_rank;
	comm->remote_size = pg_size;
	comm->local_size = pg_size;
    
	mpi_errno = MPID_VCRT_Create(comm->remote_size, &comm->vcrt);
	MPIU_ERR_CHKANDJUMP1((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**dev|vcrt_create",
			     "**dev|vcrt_create %s", "MPI_COMM_WORLD");
    
	mpi_errno = MPID_VCRT_Get_ptr(comm->vcrt, &comm->vcr);
	MPIU_ERR_CHKANDJUMP1((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**dev|vcrt_get_ptr",
			     "**dev|vcrt_get_ptr %s", "MPI_COMM_WORLD");

	for (p = 0; p < pg_size; p++)
	{
	    mpig_pg_get_vc(pg, p, &vc);
	    mpig_comm_set_vc(comm, p, vc);
	    mpig_vc_mutex_lock(vc);
	    {
		mpig_vc_inc_ref_count(vc, &vc_was_in_use, &mpi_errno, &failed);
	    }
	    mpig_vc_mutex_unlock(vc);
	}

	mpig_comm_construct(comm);
	
	/* initialize the MPI_COMM_SELF object */
	comm = MPIR_Process.comm_self;

	comm->rank = 0;
	comm->remote_size = 1;
	comm->local_size = 1;
	
	mpi_errno = MPID_VCRT_Create(comm->remote_size, &comm->vcrt);
	MPIU_ERR_CHKANDJUMP1((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**dev|vcrt_create",
			     "**dev|vcrt_create %s", "MPI_COMM_SELF");
    
	mpi_errno = MPID_VCRT_Get_ptr(comm->vcrt, &comm->vcr);
	MPIU_ERR_CHKANDJUMP1((mpi_errno), mpi_errno, MPI_ERR_OTHER, "**dev|vcrt_get_ptr",
			     "**dev|vcrt_get_ptr %s", "MPI_COMM_SELF");
    
	mpig_pg_get_vc(pg, pg_rank, &vc);
	mpig_comm_set_vc(comm, 0, vc);
	MPID_VCR_Dup(MPIR_Process.comm_world->vcr[pg_rank], &comm->vcr[0]);

	mpig_comm_construct(comm);
    }
    mpig_pg_mutex_unlock(pg);
    pg_locked = FALSE;

    /* if this process group was spawned by a MPI job, then form the MPI_COMM_PARENT inter-communicator */
#   if XXX
    {
	MPIU_Assert(has_parent == FALSE);
	/*
	 * - Get the (MPI) port of the parent
	 *
	 * - Perform a MPI_Comm_connect to the parent
	 *
	 * - Set MPIR_Process.comm_parent to the handle of the new inter-communicator
	 */
    }
#   endif
    
    /* set provided thread level */
    if (provided != NULL)
    {
	*provided = MPI_THREAD_FUNNELED;
    }

    /* indicate if the process management system has made the arguments or environment variables available */
    if (has_args != NULL)
    {
	*has_args = TRUE;
    }
    if (has_env != NULL)
    {
	*has_env = TRUE;
    }

  fn_return:
    /* mark the process group as committed, indicating that it may safely be destroyed if mpig_pg_release_ref() is called */
    if (pg != NULL)
    {
	mpig_pg_commit(pg);
    }
	
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "exiting: provided=%d, has_args=%s, has_env=%s, "
		       "mpi_errno=" MPIG_ERRNO_FMT, MPI_THREAD_FUNNELED, "true", "true", mpi_errno));
    MPIG_FUNC_EXIT(MPID_STATE_MPID_INIT);
    return mpi_errno;

  fn_fail:
    /* --BEGIN ERROR HANDLING-- */
    {
	MPIR_Process.initialized = MPICH_PRE_INIT;

	/* clean up the process group structure */
	if (pg != NULL)
	{
	    mpig_pg_mutex_unlock_conditional(pg, pg_locked);
	    mpig_pg_release_ref(pg);
	}
    
	/* XXX: track progress and clean up and allocated resources such as the process group and VCRTs */

	mpig_request_alloc_finalize();
	
	goto fn_return;
    }
    /* --END ERROR HANDLING-- */
}
/* MPID_Init() */


/*
 * MPID_Finalize()
 */
#undef FUNCNAME
#define FUNCNAME MPID_Finalize
int MPID_Finalize()
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    int n;
    int mrc;
    globus_result_t grc;
    bool_t failed;
    int mpi_errno = MPI_SUCCESS;
    MPIG_STATE_DECL(MPID_STATE_MPID_FINALIZE);

    MPIG_UNUSED_VAR(fcname);

    MPIG_FUNC_ENTER(MPID_STATE_MPID_FINALIZE);
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "entering"));

    /*
     * wait for all posted operations to complete on all communications
     *
     * NOTE: applications that leave receive operation(s) unsatisfied will hang!  such an application is erroneous, and can be
     * corrected by canceling any such operations before calling MPI_Finalize().
     */
    mrc = mpig_comm_list_wait_empty();
    MPIU_ERR_CHKANDSTMT((mrc), mrc, MPI_ERR_OTHER, {MPIU_ERR_ADD(mpi_errno, mrc);}, "**globus|comm_list_wait_empty");
    
    /* release the virtual connection reference tables for MPI_COMM_WORLD and MPI_COMM_SELF.  NOTE: the destruction of the device
       data structures in the builtin communicators occurs in mpig_comm_list_wait_empty(), so there is no need to call
       mpig_comm_destruct() here. */
    MPID_VCRT_Release(MPIR_Process.comm_world->vcrt);
    MPID_VCRT_Release(MPIR_Process.comm_self->vcrt);
    MPIR_Process.comm_world->vcrt = NULL;
    MPIR_Process.comm_self->vcrt = NULL;
    
    /* shutdown the topology information module */
    mrc = mpig_topology_finalize();
    MPIU_ERR_CHKANDSTMT((mrc), mrc, MPI_ERR_OTHER, {MPIU_ERR_ADD(mpi_errno, mrc);}, "**globus|topology_finalize");
    
    /* shutdown the communication modules.  each module is responsible for insuring that any VCs managed by it are disconnected
       before returning. */
    for (n = mpig_cm_vtables_num_entries - 1; n >= 0; n--)
    {
	mpig_cm_vtables[n]->finalize(&mpi_errno, &failed);
	MPIU_ERR_CHKANDSTMT1((failed), mpi_errno, MPI_ERR_OTHER, {;}, "**globus|cm_finalize", "**globus|cm_finalize %s",
	    mpig_cm_vtables[n]->name);
    }
    
    /* release the reference to the process group associated with MPI_COMM_WORLD */
    mpig_pg_release_ref(mpig_process.my_pg);
    mpig_process.my_pg = NULL;
    
    /* shutdown the process group management module */
    mrc = mpig_pg_finalize();
    MPIU_ERR_CHKANDSTMT((mrc), mrc, MPI_ERR_OTHER, {MPIU_ERR_ADD(mpi_errno, mrc);}, "**dev|pg_finalize");

    /* shutdown the process management module */
    mrc = mpig_pm_finalize();
    MPIU_ERR_CHKANDSTMT((mrc), mrc, MPI_ERR_OTHER, {MPIU_ERR_ADD(mpi_errno, mrc);}, "**globus|pm_finalize");
    
    /* shutdown the receive queue module */
    mrc = mpig_recvq_finalize();
    MPIU_ERR_CHKANDSTMT((mrc), mrc, MPI_ERR_OTHER, {MPIU_ERR_ADD(mpi_errno, mrc);}, "**globus|recvq_finalize");
    
    /* shutdown the request allocator module */
    mpig_request_alloc_finalize();
    
    /* deactivate globus modules */
    grc = globus_module_deactivate(GLOBUS_COMMON_MODULE);
    MPIU_ERR_CHKANDJUMP1((grc), mpi_errno, MPI_ERR_OTHER, "**globus|module_deactivate", "**globus|module_deactivate %s", "common");

   fn_return:
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "exiting: mpi_errno=" MPIG_ERRNO_FMT, mpi_errno));
    MPIG_FUNC_EXIT(MPID_STATE_MPID_FINALIZE);
    return mpi_errno;

  fn_fail:
    /* --BEGIN ERROR HANDLING-- */
    goto fn_return;
    /* --END ERROR HANDLING-- */
}
/* MPID_Finalize() */


/*
 * MPID_Abort()
 */
#undef FUNCNAME
#define FUNCNAME MPID_Abort
int MPID_Abort(MPID_Comm * const comm, const int mpi_errno, const int exit_code, const char * const error_msg)
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    MPIG_STATE_DECL(MPID_STATE_MPID_ABORT);

    MPIG_UNUSED_VAR(fcname);

    MPIG_FUNC_ENTER(MPID_STATE_MPID_ABORT);
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "entering: comm=" MPIG_PTR_FMT ",mpi_errno=" MPIG_ERRNO_FMT
		       ", exit_code=%d, error_msg=%s", (MPIG_PTR_CAST) comm, mpi_errno, exit_code, MPIG_STR_VAL(error_msg)));

    fflush(stdout);
    
    if (mpi_errno)
    {
	char * str;
	
	str = (char *) MPIU_Malloc(MPIG_ERR_STRING_SIZE);
	if (str)
	{
	    MPIR_Err_get_string(mpi_errno, str, MPIG_ERR_STRING_SIZE, NULL);
	    fprintf(stderr, "[%s:%d:%lu] %s\n", mpig_process.my_pg_id, mpig_process.my_pg_rank, mpig_thread_get_id(), str);
	    fflush(stderr);
	    MPIU_Free(str);
	}
	else
	{
	    fprintf(stderr, "[%s:%d:%lu] ERROR: unable to allocate memory needed to output an error message\n",
		mpig_process.my_pg_id, mpig_process.my_pg_rank, mpig_thread_get_id());
	    fflush(stderr);
	}
    }

    if (error_msg != NULL)
    {
	fprintf(stderr, "[%s:%d:%lu] %s\n", mpig_process.my_pg_id, mpig_process.my_pg_rank, mpig_thread_get_id(), error_msg);
	fflush(stderr);
    }

    /* MPI-2-XXX: what do we do with jobs spawned by a communicator containing one or more processes in the aborting
       communicator?  do we abort those job as well or leave them running?  should we follow the unix model and terminate any
       child jobs if they are connected directly or indirectly to the processes in the aborting communicator (see the definition
       of connected in the MPI standard)?  conversely, should we permit jobs that are no longer connected to the processes in the
       aborting communicator to continue to run, much as unix would lets a daemon process continue to run even when the invoking
       program terminats?  if it is desirable to leave disconnected child jobs running, how do we determine that no process in
       the child job is (indirectly) connected to the processes in the aborting communicator? */

    /* contact GRAMs and cancel other subjobs, then cancel our own.  XXX: in an ideal universe, we would like a core file for the
       process initiating the abort, but there is a race condition between GRAM killing the process and the process reaching the
       call to the abort() function.  I'm not sure how to resolve this.  Perhaps there is a way to tell GRAM to send a SIGABRT to
       the job(s). */
    mpig_pm_abort(exit_code);
    abort();  /* just in case... */
    
    /* fn_return: */
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "exiting"));
    MPIG_FUNC_EXIT(MPID_STATE_MPID_ABORT);
    return mpi_errno;
}
/* MPID_Abort() */


/*
 * MPID_Comm_spawn_multiple()
 */
#undef FUNCNAME
#define FUNCNAME MPID_Comm_spawn_multiple
int MPID_Comm_spawn_multiple(int count, char * array_of_commands[], char ** array_of_argv[], int array_of_maxprocs[],
			     MPID_Info * array_of_info_ptrs[], int root, MPID_Comm * comm_ptr, MPID_Comm ** intercomm,
			     int array_of_errcodes[]) 
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    int mpi_errno = MPI_SUCCESS;
    MPIG_STATE_DECL(MPID_STATE_MPID_COMM_SPAWN_MULTIPLE);

    MPIG_UNUSED_VAR(fcname);

    MPIG_FUNC_ENTER(MPID_STATE_MPID_COMM_SPAWN_MULTIPLE);
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3 | MPIG_DEBUG_LEVEL_DYNAMIC, "entering"));

    MPIU_ERR_SETFATALANDSTMT1(mpi_errno, MPI_ERR_INTERN, {goto fn_fail;}, "**notimpl", "**notimpl %s", fcname);
    
  fn_return:
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3 | MPIG_DEBUG_LEVEL_DYNAMIC, "exiting"));
    MPIG_FUNC_EXIT(MPID_STATE_MPID_COMM_SPAWN_MULTIPLE);
    return mpi_errno;

  fn_fail:
    /* --BEGIN ERROR HANDLING-- */
    goto fn_return;
    /* --END ERROR HANDLING-- */
}
/* MPID_Comm_spawn_multiple() */


/*
 * MPID_Get_processor_name()
 *
 * Returns the processor name.  Uses mpig_process.my_hostname, which is set in MPID_Init().
 */
#undef FUNCNAME
#define FUNCNAME MPID_Get_processor_name
int MPID_Get_processor_name(char * name, int * resultlen)
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    int len;
    int mpi_errno = MPI_SUCCESS;
    MPIG_STATE_DECL(MPID_STATE_MPID_GET_PROCESSOR_NAME);

    MPIG_UNUSED_VAR(fcname);

    MPIG_FUNC_ENTER(MPID_STATE_MPID_GET_PROCESSOR_NAME);
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "entering"));

    len = (int) strlen(mpig_process.my_hostname);
    if (len > 0 && len < MPI_MAX_PROCESSOR_NAME)
    {
	MPIU_Strncpy(name, mpig_process.my_hostname, (size_t) MPI_MAX_PROCESSOR_NAME);
	*resultlen = len;
    }
    else
    {
	mpi_errno = MPI_ERR_UNKNOWN;
	goto fn_fail;
    }

  fn_return:
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "exiting"));
    MPIG_FUNC_EXIT(MPID_STATE_MPID_GET_PROCESSOR_NAME);
    return mpi_errno;

  fn_fail:
    /* --BEGIN ERROR HANDLING-- */
    goto fn_return;
    /* --END ERROR HANDLING-- */
}
/* MPID_Get_processor_name() */


/*
 * MPID_Get_universe_size()
 */
#undef FUNCNAME
#define FUNCNAME MPID_Get_universe_size
int MPID_Get_universe_size(int  * universe_size)
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    int mpi_errno = MPI_SUCCESS;
    MPIG_STATE_DECL(MPID_STATE_MPID_GET_UNIVERSE_SIZE);

    MPIG_UNUSED_VAR(fcname);

    MPIG_FUNC_ENTER(MPID_STATE_MPID_GET_UNIVERSE_SIZE);
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "entering"));

    /* FIXME: someday we might want to allow the user to set an environment variable specifying the universe size, or have
       mpiexec compute it from a known hosts file, but for now set the size to "unavailable". */
    *universe_size = MPIR_UNIVERSE_SIZE_NOT_AVAILABLE;
    
    /* fn_return: */
    MPIG_DEBUG_PRINTF((MPIG_DEBUG_LEVEL_FUNC | MPIG_DEBUG_LEVEL_ADI3, "exiting"));
    MPIG_FUNC_EXIT(MPID_STATE_MPID_GET_UNIVERSE_SIZE);
    return mpi_errno;

#if 0    
  fn_fail:
    {   /* --BEGIN ERROR HANDLING-- */
	*universe_size = MPIR_UNIVERSE_SIZE_NOT_AVAILABLE;
	goto fn_return;
    }   /* --END ERROR HANDLING-- */
#endif
}
/* MPID_Get_universe_size() */


/*
 * MPID_GPID_Get([IN] comm, [IN] rank, [OUT] gpid[2])
 *
 * MPI-2-FIXME: THIS IS NOT RIGHT FOR MPI-2 FUNCTIONALITY!!!  gpid[0] needs to be unique to a process group.
 *
 * NOTE: for MPI-2 functionality, the global id needs to be bigger than an int.  We could hash the (host, pid(p0), etc.) tuple
 * into an int if necessary, but it would be better if the if were guaranteed to be unique.  for this, it seems best if the
 * device defined the data format.  the device could also define a matching MPI datatype that the upper layer could use for
 * communicating the ids.
 */
#undef FUNCNAME
#define FUNCNAME MPID_GPID_Get
int MPID_GPID_Get(MPID_Comm * comm, int rank, int gpid[])
{
    const char fcname[] = MPIG_QUOTE(FUNCNAME);
    mpig_vc_t * vc;
    int mpi_errno = MPI_SUCCESS;

    MPIG_UNUSED_VAR(fcname);

    mpig_comm_get_vc(comm, rank, &vc);
    gpid[0] = 0;
    gpid[1] = vc->pg_rank;

    return mpi_errno;
}
/* MPID_GPID_Get() */
