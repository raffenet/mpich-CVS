
        		 MPICH2 Early Release

This tarball contains an early release of MPICH2.  It has been
tested by us in our own environment, but not extensively tested
by outside users (This is where you come in!).  Depending
on your system, it may not even compile.  If you are interested in
what the next generation of MPICH will look like, or for helping us
harden this version for wider distribution, this tarball is for
you.  If you are looking for an implementation of MPI for use in
building and running your favorite application(s), please obtain the
MPICH 1.2.X distribution from http://www.mcs.anl.gov/mpi/mpich.

If you have difficulties with this release of MPICH2, please send
mail to mpich2-maint@mcs.anl.gov.

Currently the only communication layer fully supported in MPICH2 is the
"TCP channel device", although others are in preparation, as you can see
from the code here.  Also, this device currently supports only homogenous
environments.  

To build MPICH2 with the TCP channel device, do the following:

    tar xzf mpich2.tar.gz
    cd mpich2-<VERSION>
    ./configure
    make

(If your tar does not support the z option, use

   gunzip -c mpich2.tar.gz | tar xf -

for the first line).  (VPATH builds are supported as well; see below).

You should now have a complete build of MPICH2, and the executable
commands needed to start MPI processes are in mpich2-<VERSION>/bin.  You
should add that directory to your PATH.

If you wish to install MPICH2 in a directory other than the one you
build it in, you should build MPICH2 as follows.

    ./configure --prefix=<INSTALL_DIR>
    make
    make install

Then the necessary executables will be in <INSTALL_DIR>/bin, and you
should add it to your PATH.

Example and test programs (both source and executables) can be found in
./examples and ./test/mpi/basic, respectively.  To run any of these
programs, you will need to start the MPD process management daemon.
More on MPD can be found in mpich2/src/pm/mpd/README.  An important
prerequisite is that you need to have Python 2.2 installed.  (MPICH2
will work with multiple process managers; the version of MPD implemented
using Python is just one such example.  Later versions of MPICH2 will
provide additional process managers).

To use some features of MPD, such as the MPI-2 standard form of mpiexec
or mpdrun/mpirun with XML file arguments, you will need PyXML and an XML
parser such as expat installed.  

Python 2.2 is available from www.python.org.  PyXML and expat are
available from pyxml.sourceforge.net.

Before running MPD you need to set up the following file in your home
directory on all the machines where you will be running (or in your home
directory on a file system shared by all the nodes).

   touch ~/.mpd.conf
   chmod 600 ~/.mpd.conf
   echo "password=<YOUR_MPD_PASSWORD_HERE>" >>~/.mpd.conf
   ./bin/mpd &

The password should *not* be the same as any other password that you use;
this password is used exclusively within the MPD system.

Should you wish to setup a MPD ring across multiple machines, more
advanced instructions for MPD can be found in mpich2/src/pm/mpd/README.

Once you have MPD running, you may run the hello world program as
follows.

    cd examples
    mpiexec -n 2 hellow

To shut MPD down, run

    mpdallexit

What compiles but doesn't work
------------------------------
We don't guarantee that *anything* works yet.  However, we have run MPICH2 
against both the MPICH-1 test suite and an updated and correct version of the 
Intel test suite.  MPICH2 passes most of these tests, including most error 
handling.  Among the routines that compile but that are known not to work yet
are: 

MPI_Get_elements for partial types


Other known issues:
The various free routines do not yet free all internal objects, so memory
leaks are certain.  However, most MPI programs should not have any problems.

Testing Status
--------------
We run regular tests of the MPI-1 functions.  We are using both the MPICH-1
test suite and the Intel test suite (with corrections). 
The current status is available at 
http://www.mcs.anl.gov/mpi/mpich/micronotes/mpich2-tests .  

VPATH Builds
------------
MPICH2 supports building MPICH in a different directory tree than the one
where the MPICH2 source is installed.  This often allows faster building, as
the sources can be placed in a shared filesystem and the builds done in a
local (and hence usually much faster) filesystem.  To make this clear,
the following example assumes that the sources are placed in 
/usr/me/mpich2-10-25-02, the build is done in /tmp/me/mpich2, and the 
installed version goes into /usr/local/mpich2-test:

    cd /usr/me
    tar xzf mpich2-<VERSION>.tar.gz
    cd /tmp/me
    # Assume /tmp/me already exists
    mkdir mpich2
    cd mpich2
    /usr/me/mpich2-<VERSION>/configure --prefix=/usr/local/mpich2-test
    make
    make install

Release Notes
-------------
Most of the testing to date has been in a GNU environment under Linux, albeit
with many of gcc's warning options turned on.  Other environments with 
stricter compilers may find compilation problems.  Testing has been thorough
in the GNU/Linux environment, with both the MPICH1 and Intel (corrected)
test suites showing few problems.  See
http://www.mcs.anl.gov/mpi/mpich/micronotes/mpich2-tests for the current
status.

There are many features built into MPICH2.  If you are exploring MPICH2 as
part of a development project the following configure options are important:

Performance Options:
 --enable-fast - Turns off error checking and collection of internal 
                 timing information
 --enable-timing=no - Turns off just the collection of internal timing
                 information
MPI Features:
  --enable-romio - Build the ROMIO implementation of MPI-IO.  
  --with-file-system - When used with --enable-romio, specifies filesystems
                 ROMIO should support.  See README.romio

Language bindings:
  --enable-f77 - Build the Fortran 77 bindings.  This has been tested with
                 the Fortran parts of the Intel test suite.  Fortran 90
		 is not yet available.
  --enable-cxx - Build the C++ bindings.  This has *not* been tested and
                 is not quite ready for use.  Wait for the next release.

Cross compilation:
  --with-cross=filename - Provide values for the tests that required
                 running a program, such as the tests that configure
		 uses to determine the sizes of the basic types.
		 This should be a fine in Bourne shell format containing
		 varable assignment of the form
                       CROSS_SIZEOF_INT=2
                 for all of the CROSS_xxx variables.  A list will
		 be provided in later releases; for now, look at the 
		 configure.in files.

Error checking and reporting:
  --enable-error-checking=level - Control the amount of error checking.
                 Currently, only "no" and "all" is supported; all is the 
		 default.
  --enable-error-messages=level - Control the aount of detail in error
                 messages.  By default, MPICH2 provides instance-specific
		 error messages, but with this option, MPICH2 can be
		 configured to provide less detailed messages.  This
		 may be deesirable on small systems, such as clusters
		 built from game consoles or high-density massively
		 parallel systems.

Compilation options for development:
  --enable-g=value - Controls the amount of debugging information
                 collected by the code.  The most useful choice here is
		 dbg, which compiles with -g.
  --enable-coverage - An experimental option for enable GNU coverage
                 analysis.
  --with-logging=name - Select a logging library for recording the 
                 timings of the internal routines.  We have used this
		 to understand the performance of the internals of MPICH2.
		 Wait for the next release for detailed instructions.

Alternate Process Managers:
  --with-pm=forker - Forker is a simple process manager that creates all
                 processes on the same machine.  This is an alternative
		 to the default (mpd), and illustrates how to interface
		 MPICH2 to other process managers without changing the
		 implementation of the communication device.
