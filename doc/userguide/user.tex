\documentclass[dvipdfm,11pt]{article}
\usepackage[dvipdfm]{hyperref} % Upgraded url package
\parskip=.1in

\begin{document}
\markright{MPICH2 User's Manual}
\title{MPICH2 User's Manual\\
Version 0.2\\
DRAFT of \today\\
Mathematics and Computer Science Division\\
Argonne National Laboratory}

\author{William Gropp\\
Ewing Lusk\\
David Ashton\\
Darius Buntinas\\
Ralph Butler\\
Anthony Chan\\
Rob Ross\\
Rajeev Thakur\\
Brian Toonen}

\maketitle

\cleardoublepage

\pagenumbering{roman}
\tableofcontents
\clearpage

\pagenumbering{arabic}
\pagestyle{headings}


Here is a basic outline for the document

1. Setting paths

2. Compiling and linking

  2a. Chosing compilers (e.g., you need not use the same compiler that
      MPICH was built with)

  2b. Shared libraries

  2c. Special issues for Fortran 77 and Fortran 90
 
      (mostly the choice module, but also the various name mangling issues)

3. Running with mpiexec

  3a. mpiexec standard options (from MPI-2)

  3b. device and pm specific options

  3c. environment variables

      for example, \texttt{MPIEXEC\_TIMEOUT}

  3d. managing stdin/out/err

  3e. managing files (staging?), including executables

4. Examples 

   4a. Simple programs
  
   4b. Benchmarking (similar or identical to text in the installation guide)

   4c. Pointers to other resources (books, tutorials, sample programs)

5. Debugging

   5a. Working with single-process debuggers

   5b. Working with parallel debuggers such as Totalview

6. Troubleshooting


\section{Introduction}
\label{sec:introduction}

This manual assumes that MPICH2 has already been installed.  For
instructions on how to install MPICH2, see the MPICH2 Installation Guide,
or the README in the top-level MPICH2 directory.  This manual will
explain how to compile, link, and run MPI applications, and use certain
tools that come with MPICH2.


\section{Setting Paths}
\label{sec:paths}

You will have to know the directory where MPICH2 has been installed.
(Either you installed it there yourself, or your systems administrator has
installed it.  One place to look in this case might be \texttt{/usr/local}.)
You will need to put the \texttt{bin} subdirectory of that directory in
your path.  This will give you access to assorted MPICH2 commands to
compile, link, and run your programs conveniently.  Other commands in
this directory manage parts of the run-time environment and execute
tools.  

One of the first commands you might run is \texttt{mpich2version}
(\textbf{Make it so.}, to find out the exact version and configuration
of MPICH2 you are working with.  Some of the material in this manual
depends on just what version of MPICH2 you are using and how it was
configured at installation time.


\section{Compiling and Linking}
\label{sec:compiling}

A convenient way to compile and link your program is by using scripts
that use the same compiler that MPICH2 was built with.  These are
\texttt{mpicc}, \texttt{mpicxx}, \texttt{mpif77}, and \texttt{mpif90},
for C, C++, Fortran 77, and Fortran 90 programs, respectively.  If any
of these commands are missing, it means that MPICH2 was configured
without support for that particular language.

\subsection{Specifying Compilers}
\label{sec:specifying-compilers}

You need not use the same compiler that MPICH2 was built with.

\subsection{Shared Libraries}
\label{sec:shared-libraries}

Shared libraries are currently not supported.  We are working on it.

\subsection{Special Issues for Fortran}
\label{sec:fortran}

\begin{itemize}
\item The choice module for Fortran 90
\item Various name-mangling issues
\end{itemize}
\section{Running Programs with \texttt{mpiexec}}
\label{sec:mpiexec}

The MPI Standard describes \texttt{mpiexec} as a suggested way to run
MPI programs.  MPICH2 implements the \texttt{mpiexec} standard, and also
provides some extensions.


\subsection{Standard \texttt{mpiexec}}
\label{sec:mpiexec-standard}

Here we describe the standard \texttt{mpiexec} arguments from the MPI-2
Standard~\cite{mpi-forum:mpi2-journal}.  The simplest form of a command
to start an MPI job is 
\begin{verbatim}
     mpiexec -n 32 a.out
\end{verbatim}
to start the executable \texttt{a.out} with 32 processes (providing an
\texttt{MPI\_COMM\_WORLD} of size 32 inside the MPI application).  Other
options are supported, for specifying hosts to run on,  search paths for
executables, working directories, and even a more general way of
specifying a number of processes.  Multiple sets of processes can be run
with different exectuables and different values for their arguments,
with ``\texttt{:}'' separating the sets of processes, as in:
\begin{verbatim}
    mpiexec -n 1 -host loginnode master : -n 32 -host smp slave
\end{verbatim}
The \texttt{-file} argument allows one to specify a file containing the
specifications for process sets on separate lines in the file.  This
makes it unnecessary to have long command lines for \texttt{mpiexec}.  

(See p. 353 of MPI--The Complete Reference, Volume 1, second edition.)

Currently the \texttt{-soft} argument is accepted but not supported.

\subsection{Extensions for All Process Management Environments}
\label{sec:extensions-uniform}

Some \texttt{mpiexec} arguments are specific to particular communication
subsystems (``devices'') or process management environments (``process
managers'').  Our intention is to make all arguments as uniform as
possible across devices and process managers.  For the time being we
will document these separately.

\subsection{Extensions for Various Process Management Environments}
\label{sec:extensions-various}

\subsubsection{\texttt{mpiexec} arguments for MPD}
\label{sec:extensions-mpd}

The default configuration of MPICH2 chooses the MPD process manager and
the ``simple'' process management interface.  MPD provides a version of
\texttt{mpiexec} that supports both the standard arguments described in
Section~\ref{sec:mpiexec-standard} and other arguments described in this
section.  MPD also provides a number of commands for querying the MPD
process management environment interacting with jobs it has started. 

Before running \texttt{mpiexec}, the runtime environment must be
established.  In the case of MPD, the daemons must be running.  See
Section~\ref{sec:managing-mpd} for how to run and manage the MPD daemons.

We assume that the MPD ring is up; that is, you can do:
\begin{verbatim}
    mpdtrace
\end{verbatim}
and it will output a list of nodes on which you can run MPI programs.
Now you are ready to run a program with \texttt{mpiexec}.  Let us assume
that you have compiled and linked the program \texttt{cpi} (in the
\texttt{bin/examples/directory}.  (\textbf{Make it so.}) The simplest
thing to do is
\begin{verbatim}
    mpiexec -n 5 cpi
\end{verbatim}
to run \texttt{cpi} on five nodes.  The process management system (such
as MPD) will choose machines to run them on, and \texttt{cpi} will tell
you where each is running.

The MPI-2 standard specifies the syntax and semantics of the arguments
\texttt{-n}, \texttt{-path},\texttt{-wdir}, \texttt{-host},
\texttt{-file}, \texttt{-configfile}, and \texttt{-soft}.  All of these
are currently implemented for MPD's \texttt{mpiexec} except
\texttt{-soft}.  Each of these is what we call a ``local'' option, since
its scope is the processes in the set of processes described between
colons, or on separate lines of the file specified by
\texttt{-configfile}.  We add some extensions that are local in this way
and some that are ``global'' in the sense that they apply to all the
processes being started by the invocation of \texttt{mpiexec}.

The Standard provides a way to pass different arguments to different
application processes, but does not provide a way to pass environment
variables.  The local parameter \texttt{-env} does this for one set of
processes.  That is,
\begin{verbatim}
   mpiexec -n 1 -env FOO BAR a.out : -n 2 -env BAZZ FAZZ b.out
\end{verbatim}
makes \texttt{BAR} the value of environment variable \texttt{FOO} on the
first process, running the executable \texttt{a.out}, and gives the
environment variable \texttt{BAZZ} the value \texttt{FAZZ} on the second
two processes, running the executable \texttt{b.out}.

The global parameter \texttt{-genv} can be used to pass the same
environment variables to all processes.  That is,
\begin{verbatim}
    mpiexec -genv FOO BAR -n 2 a.out : -n 4 b.out
\end{verbatim}
makes \texttt{BAR} the value of the environment variable \texttt{FOO} on
all six processes.  If \texttt{-genv} appears, it must appear in the
first group.  If both \texttt{-genv} and \texttt{-env} are used, the
\texttt{-env}'s add to the environment specified or added to by the
\texttt{-genv} variables.  If there is only one set of processes (no
``\texttt{:}''), the \texttt{-genv} and \texttt{-env} are equivalent.

The local parameter \texttt{-setenvall} is an abbreviation for passing
the entire environment in which \texttt{mpiexec} is executed.  The
global version of it is \texttt{-gsetenvall}.  This global version is
implicitly present.  To turn it off use \texttt{-nosetenvall} and
\texttt{-gnosetenvall}.

Some extension parameters have only global versions.  They are
\begin{description}
\item[\texttt{-l}] provides rank labels for lines of \texttt{stdout} and
  \texttt{stderr}.  These are a bit obscure for processes that have
  been explicitly spawned, but are still useful.
\item[\texttt{-usize}] sets the ``universe size'' that is retrieved by the MPI
  attribute \texttt{MPI\_UNIVERSE\_SIZE} on \texttt{MPI\_COMM\_WORLD}. 
\item[\texttt{-gdb}] invokes \texttt{gdb} on the processes as they are started.  This is an
  alternate way of invoking \texttt{mpigdb}.
\item[\texttt{-bnr}] is used when one wants to run executables that have been
  compiled and linked using the \texttt{ch\_p4mpd} or \texttt{myrinet} device in
  MPICH1.  The MPD process manager provides backward compatibility in
  this case. 
\item[-ncpus] is used when allowing MPD to pick the hosts: it tells MPD
  how many processes should be started by each MPD in the ring as the
  processes are started in round-robin fashion.
\end{description}

\subsubsection{\texttt{mpiexec} arguments for SMPD}
\label{sec:extensions-smpd}

SMPD is an alternate process manager that runs on both Unix and Windows.
It can launch jobs across both platforms if the binary formats match 
(big/little endianness and size of C types - int,long,void*,etc).

mpiexec for smpd accepts the standard MPI-2 mpiexec options.  Execute
\begin{verbatim}
    mpiexec
\end{verbatim}
or
\begin{verbatim}
    mpiexec -help2
\end{verbatim}
to print the usage options.  Typical usage:
\begin{verbatim}
    mpiexec -n 10 myapp.exe
\end{verbatim}

All options to mpiexec:
\begin{description}
\item[\texttt{-n x}]
\item[\texttt{-np x}]\mbox{}\\
  launch x processes
\item[\texttt{-localonly x}]
\item[\texttt{-np x -localonly}]\mbox{}\\
  launch x processes on the local machine
\item[\texttt{-machinefile filename}]\mbox{}\\
  use a file to list the names of machines to launch on
\item[\texttt{-host hostname}]\mbox{}\\
  launch on the specified host.
\item[\texttt{-hosts n host1 host2 ... hostn}]
\item[\texttt{-hosts n host1 m1 host2 m2 ... hostn mn}]\mbox{}\\
  launch on the specified hosts.
  In the second version the number of processes = m1 + m2 + ... + mn
\item[\texttt{-dir drive:$\backslash$my$\backslash$working$\backslash$directory}]
\item[\texttt{-wdir /my/working/directory}]\mbox{}\\
  launch processes with the specified working directory. (-dir and -wdir are
equivalent)
\item[\texttt{-env var val}]\mbox{}\\
  set environment variable before launching the processes
%\item[\texttt{-nocolor}]\mbox{}\\
%  don't use process specific output coloring
%\item[\texttt{-nompi}]\mbox{}\\
%  launch processes without the mpi startup mechanism
\item[\texttt{-exitcodes}]\mbox{}\\
  print the process exit codes when each process exits.
\item[\texttt{-noprompt}]\mbox{}\\
  prevent mpiexec from prompting for user credentials.  Instead errors will
be printed and mpiexec will exit.
% This may be implemented.
%\item[\texttt{-localroot}]\mbox{}\\
%  launch the root process without smpd if the host is local.
%  (This allows the root process to create windows and be debugged.)
\item[\texttt{-port port}]
\item[\texttt{-p port}]\mbox{}\\
  specify the port that smpd is listening on.
\item[\texttt{-phrase passphrase}]\mbox{}\\
  specify the passphrase to authenticate connections to smpd with.
\item[\texttt{-smpdfile filename}]\mbox{}\\
  specify the file where the smpd options are stored including the 
passphrase. (unix only option)
\item[\texttt{-soft Fortran90\_triple}]\mbox{}\\
  acceptable number of processes to launch up to maxprocs
\item[\texttt{-path search\_path}]\mbox{}\\
  search path for executable, ; separated
% This will probably not be implemented.
%\item[\texttt{-arch architecture}]\mbox{}\\
%  sun, linux, rs6000, ...
\item[\texttt{-timeout seconds}]\mbox{}\\
  timeout for the job.
\end{description}
Windows specific options:
\begin{description}
\item[\texttt{-map drive:$\backslash$$\backslash$host$\backslash$share}]\mbox{}\\
  map a drive on all the nodes
  this mapping will be removed when the processes exit
\item[\texttt{-logon}]\mbox{}\\
  prompt for user account and password
\item[\texttt{-pwdfile filename}]\mbox{}\\
  read the account and password from the file specified
  put the account on the first line and the password on the second
\item[\texttt{-nomapping}]\mbox{}\\
  don't try to map the current directory on the remote nodes
\item[\texttt{-nopopup\_debug}]\mbox{}\\
  disable the system popup dialog if the process crashes
\item[\texttt{-dbg}]\mbox{}\\
  catch unhandled exceptions
\item[\texttt{-priority class[:level]}]\mbox{}\\
  set the process startup priority class and optionally level.\mbox{}\\
  class = 0,1,2,3,4   = idle, below, normal, above, high\mbox{}\\
  level = 0,1,2,3,4,5 = idle, lowest, below, normal, above, highest\mbox{}\\
  the default is -priority 1:3
\item[\texttt{-register}]\mbox{}\\
  encrypt a user name and password to the Windows registry.
\item[\texttt{-remove}]\mbox{}\\
  delete the encrypted credentials from the Windows registry.
\item[\texttt{-validate [-host hostname]}]\mbox{}\\
  validate the encrypted credentials for the current or specified host.
\end{description}

\subsubsection{\texttt{mpiexec} arguments for Forker}
\label{sec:extensions-forker}


\subsection{Environment Variables}
\label{sec:envvars}

Several environment variables can be used to control the execution of
MPICH2 programs.

\begin{description}
\item[\texttt{MPIEXEC\_TIMEOUT}] The maximum number of seconds that an MPI
  application will be allowed to run.  Then it will be terminated.
\item[\texttt{MPIEXEC\_BNR}] causes the MPD process manager to run in
  backward-compatibility mode, supporting the BNR process management
  interface rather than PMI.
\end{description}

\section{Managing the Process Management Environment}
\label{sec:managing-pme}

Some of the process managers supply user commands that can be used to
interact with the process manager and to control jobs.  In this section
we describe user commands that may be useful.

\subsection{MPD}
\label{sec:managing-mpd}

\begin{description}
\item[\texttt{mpdtrace}] lists all the MPD daemons that are running.  The
  \texttt{-l} option lists full hostnames and the port where the mpd is
  listening. 
\item[\texttt{mpdlistjobs}] lists the jobs that the mpd's are running.
  Jobs are identified by the name of the mpd where they were submitted
  and a number.
\item[\texttt{mpdkilljob}] kills a job specified by the name returned by
  \texttt{mpdlistjobs }
\item[\texttt{mpdsigjob}] delivers a signal to the named job.  Signals
  are specified by name or number.
\end{description}
You can use keystrokes to provide signals in the usual way, where
\texttt{mpiexec} stands in for the entire parallel application.  That
is, if \texttt{mpiexec} is being run in a Unix shell in the foreground,
you can use \verb+^C+ to send a \texttt{SIGINT} to the processes, or
\verb+^Z+ to suspend all of them.  A suspended job can be continued in
the usual way.

Precise argument formats can be obtained by passing any MPD command the
\texttt{--help} or \texttt{-h} argument.  More details can be found in
the \texttt{README} in the mpich2 top-level directory or the
\texttt{README} file in the MPD directory \texttt{mpich2/src/pm/mpd}.


\section{Debugging}
\label{sec:debugging}

Debugging parallel programs is notoriously difficult.  Here we describe
a number of approaches, some of which depend on the exact version of
MPICH2 you are using. 


\subsection{\texttt{mpigdb}}
\label{sec:mpigdb}

If you are using the MPD process manager, you can use the command
\texttt{mpigdb} instead of \texttt{mpiexec} to execute a program with
each process running under the control of the \texttt{gdb} sequential
debugger.  \texttt{mpigdb} helps control the multiple instances of
\texttt{gdb} by sending \texttt{stdin} either to all processes or to a
selected process and by labeling and merging output.  The following
script of an \texttt{mpigdb} session gives an idea of how this works.
Input keystrokes are sent to all processes unless specifially directed
by the ``z'' command.

\begin{small}
\begin{verbatim}
ksl2% mpigdb -n 10 cpi
0-9:  (gdb) l
0-9:  5 double f(double);
0-9:  6 
0-9:  7 double f(double a)
0-9:  8 {
0-9:  9     return (4.0 / (1.0 + a*a));
0-9:  10        }
0-9:  11        
0-9:  12        int main(int argc,char *argv[])
0-9:  13        {
0-9:  14            int done = 0, n, myid, numprocs, i;
0-9:  (gdb) 
0-9:  15            double PI25DT = 3.141592653589793238462643;
0-9:  16            double mypi, pi, h, sum, x;
0-9:  17            double startwtime = 0.0, endwtime;
0-9:  18            int  namelen;
0-9:  19            char processor_name[MPI_MAX_PROCESSOR_NAME];
0-9:  20        
0-9:  21            MPI_Init(&argc,&argv);
0-9:  22            MPI_Comm_size(MPI_COMM_WORLD,&numprocs);
0-9:  23            MPI_Comm_rank(MPI_COMM_WORLD,&myid);
0-9:  24            MPI_Get_processor_name(processor_name,&namelen);
0-9:  (gdb) 
0-9:  25        
0-9:  26            fprintf(stdout,"Process %d of %d is on %s\n",
0-9:  27                    myid, numprocs, processor_name);
0-9:  28            fflush(stdout);
0-9:  29        
0-9:  30            n = 10000;                  /* default # of rectangles */
0-9:  31            if (myid == 0)
0-9:  32                startwtime = MPI_Wtime();
0-9:  33        
0-9:  34            MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
0-9:  (gdb) b 30
0-9:  Breakpoint 2 at 0x4000000000002541: file /home/lusk/mpich2/examples/cpi.c, line 30.
0-9:  (gdb) r
0-9:  Continuing.
0:  Process 0 of 10 is on ksl2
1:  Process 1 of 10 is on ksl2
2:  Process 2 of 10 is on ksl2
3:  Process 3 of 10 is on ksl2
4:  Process 4 of 10 is on ksl2
5:  Process 5 of 10 is on ksl2
6:  Process 6 of 10 is on ksl2
7:  Process 7 of 10 is on ksl2
8:  Process 8 of 10 is on ksl2
9:  Process 9 of 10 is on ksl2
0-9:  
0-9:  Breakpoint 2, main (argc=1, argv=0x60000fffffffb4b8)
0-9:      at /home/lusk/mpich2/examples/cpi.c:30
0-9:  30            n = 10000;                  /* default # of rectangles */
0-9:  (gdb) n
0-9:  31            if (myid == 0)
0-9:  (gdb) n
0:  32          startwtime = MPI_Wtime();
1-9:  34            MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
0-9:  (gdb) z 0
0:  (gdb) n
0:  34      MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD);
0:  (gdb) z
0-9:  (gdb) w
0-9:  Ambiguous command "w": watch, whatis, where, while, while-stepping, ws.
0-9:  (gdb) where
0-9:  #0  main (argc=1, argv=0x60000fffffffb4b8)
0-9:      at /home/lusk/mpich2/examples/cpi.c:34
0-9:  (gdb) n
0-9:  36            h   = 1.0 / (double) n;
0-9:  (gdb) 
0-9:  37            sum = 0.0;
0-9:  (gdb) 
0-9:  39            for (i = myid + 1; i <= n; i += numprocs)
0-9:  (gdb) 
0-9:  41                x = h * ((double)i - 0.5);
0-9:  (gdb) 
0-9:  42                sum += f(x);
0-9:  (gdb) 
0-9:  39            for (i = myid + 1; i <= n; i += numprocs)
0-9:  (gdb) 
0-9:  41                x = h * ((double)i - 0.5);
0-9:  (gdb) 
0-9:  42                sum += f(x);
0-9:  (gdb) 
0-9:  39            for (i = myid + 1; i <= n; i += numprocs)
0-9:  (gdb) 
0-9:  41                x = h * ((double)i - 0.5);
0-9:  (gdb) 
0-9:  42                sum += f(x);
0-9:  (gdb) 
0-9:  39            for (i = myid + 1; i <= n; i += numprocs)
0-9:  (gdb) 
0-9:  41                x = h * ((double)i - 0.5);
0-9:  (gdb) 
0-9:  42                sum += f(x);
0-9:  (gdb) 
0-9:  39            for (i = myid + 1; i <= n; i += numprocs)
0-9:  (gdb) 
0-9:  41                x = h * ((double)i - 0.5);
0-9:  (gdb) 
0-9:  42                sum += f(x);
0-9:  (gdb) 
0-9:  39            for (i = myid + 1; i <= n; i += numprocs)
0-9:  (gdb) 
0-9:  41                x = h * ((double)i - 0.5);
0-9:  (gdb) 
0-9:  42                sum += f(x);
0-9:  (gdb) p sum
0:  $1 = 19.999875951497799
1:  $1 = 19.999867551672725
2:  $1 = 19.999858751863549
3:  $1 = 19.999849552071328
4:  $1 = 19.999839952297158
5:  $1 = 19.999829952542203
6:  $1 = 19.999819552807658
7:  $1 = 19.999808753094769
8:  $1 = 19.999797553404832
9:  $1 = 19.999785953739192
0-9:  (gdb) c
0-9:  Continuing.
0:  pi is approximately 3.1415926544231256, Error is 0.0000000008333325
1-9:  
1-9:  Program exited normally.
1-9:  (gdb) 0:  wall clock time = 44.909412
0:  
0:  Program exited normally.
0:  (gdb) q
0-9:  MPIGDB ENDING
ksl2% 
\end{verbatim}
\end{small}

\section{MPICH2 under Windows}
\label{sec:windows}

\subsection{Directories}
\label{sec:windir}

The default installation of MPICH2 is in
\texttt{C:$\backslash$Program Files$\backslash$MPICH2}. Under the installation
directory are three sub-directories: \texttt{include}, \texttt{bin}, and
\texttt{lib}.  The \texttt{include} and \texttt{lib} directories contain
the header files and libraries necessary to compile MPI applications.  
The \texttt{bin} directory contains the process manager, \texttt{smpd.exe},
and the the MPI job launcher, \texttt{mpiexec.exe}.  The dlls that implement
MPICH2 are copied to the Windows system32 directory.

\subsection{Compiling}
\label{sec:wincompile}

The libraries in the lib directory were compiled with MS Visual C++ .NET 2003
and Intel Fortran 8.0 with the default MPICH2 socket channel.  These 
compilers and any others that can link with the MS .lib files can be used to
create user applications.  gcc and g77 for cygwin can be used with the 
libmpich*.a libraries.

For MS Developer Studio users:  Create a project and add
\texttt{C:$\backslash$Program Files$\backslash$MPICH2$\backslash$include} 
to the include path and \texttt{C:$\backslash$Program Files$\backslash$MPICH2$\backslash$lib} 
to the library path.  Add cxx.lib and mpich2.lib to the Release target link 
command.  Add cxxd.lib and mpich2d.lib to the Debug target.

Intel Fortran 8 users add fmpich2d.lib to the link command in addition to the
libraries mentioned above.

cygwin users use libmpich2.a libfmpich2g.a.

\subsection{Running}
\label{sec:winrun}

MPI jobs are run from a command prompt using mpiexec.exe.  See section \ref{sec:extensions-smpd} 
on mpiexec for smpd for a description of the options to mpiexec.


\bibliographystyle{plain}
\bibliography{user,/home/MPI/allbib}

\end{document}
