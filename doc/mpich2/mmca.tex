\includeversion{comment}

\def\mpiobj#1{\code{#1}\index{#1}}
\def\term#1{\emph{\textbf{#1}}}
\def\todo#1{\emph{\textbf{TODO:} #1}}
\def\Q#1{\emph{\textbf{QUESTION:} #1}}
\newenvironment{discussion}{\em\textbf{Discussion:} }{}
\newenvironment{implnote}{\textbf{Note to implementor:} }{}

\newenvironment{cmt}[1][]%
  {\begin{comment}\em\textbf{Comment\ifthenelse{\equal{#1}{}}{}{ [#1]}:}}%
  {\end{comment}}
%\newenvironment{cmt}{\begin{comment}\em\textbf{Comment:} }{\end{comment}}
%\newenvironment{cmtx}[1]{\begin{comment}\em\textbf{Comment [#1]:} }
%  {\end{comment}}

\section{Multi-method Communication Architecture}

\begin{cmt}
  Remember this comment:
  is it ok to use the term operation in here?  is there a better one?  we could
  use the term ``request''.  operation isn't too confusing right now, but it
  may be later.  then again, the MPI standard talks about ``posting nonblocking
  operations''...
\end{cmt}


In this section, we present a multi-method communication architecture
for MPICH2.

A \term{communication method} is a means for passing messages between two
processes.  Because different methods have different connectivity and
performance characteristics, it is desirable for an MPI implementation to
support multiple methods simultaneously.  For example, in a cluster of SMPs one
might want to use a shared memory method for communicating within a node and a
TCP/IP method for communicating between nodes.


Rather than present the entire architecture at once, we will start
with a basic system and modify it as we add capabilities.  The reason
for such a presentation is two-fold.  First, the intricate details of
the architecture are difficult to understand at first glance.  We hope
that by incrementally presenting features of the architecture, the
motivation will be clearer and the reader will be better served.
Second, the organization of this section suggests a plan for
developing a prototype implementation of the multi-method
architecture.  Many of the ideas presented within the section are as
of yet unproven, and would be benefit greatly from rapid prototyping
and performance analysis.

%==============================================================================

% \subsection{Architecture Overview}

%==============================================================================

\subsection{Simple Messaging}

% goal: describe components necessary for unoptimized, multi-method
% point-to-point
% 
% narrow scope for this subsection: no wildcards, persistent sends, etc...(look
% at lists below :)).  also not dealing with complex datatypes, heterogeneity,
% vendor MPI.

In this section we will describe the components necessary for an unoptimized,
multi-method, point-to-point (P2P) messaging system.  The scope of this system
is rather restricted with respect to MPI capabilities; wildcards, persistent
sends, request cancellation, complex datatypes, heterogeneity, and approaches
for reducing data copies will all be ignored for now.  We will address these
issues later in the document.

\subsubsection{Overview}

% major steps in point-to-point communication:
% \begin{itemize}
% \item posting
% \item progress
% \item completion
% \end{itemize}
% 
% go through one step at a time
% 
% for each step:
% - components used in that step? (also assumed knowledge?)
% - paragraph summary of what happens in that step
% 

One can break P2P communication into three major steps: message
posting, progress of transfer, and message completion.  In this section we
describe these steps at a high level and introduce some of the components that
will be involved in each step.

% scenario: send posted, recv posted, data arrives after recv posted.
% - trivial mpi program example here
% - note that there is another ordering, and we will discuss that in the
%   walkthrough
% 

For our overview we will concentrate our discussion on a simple scenario.  In
our scenario one process is sending a contiguous data region to another.  Both
are using nonblocking MPI calls, and execution order occurs such that the data
arrives after the receive has been posted.  This is of course not the only
possible ordering, and we will discuss other possibilities in
Section~\ref{sssec:walkthrough}.

\begin{cmt}
  include a figure showing the actual code snippets
\end{cmt}

% posting (async send case)
% - allocation/initialization of MPI request (must initialize completion counter)
% - determine the vc from the communicator (so we can get to method)
% - calling of method function to post

An asynchronous send (\mpifunc{MPI_ISEND}) first results in the allocation and
initialization of a \mpiobj{MPI_Request} object (described previously in XXX).
A \term{completion counter} is included in this structure, and it is
initialized at this point to 1 (corresponding to the number of method sends
which must complete).

Next the \term{virtual connection} (VC) is determined from the communicator
passed into the send call.  A reference to the appropriate method for moving
data on this VC is found within the VC object.

Finally the method function for posting a send is called, passing it the buffer
and envelope information supplied to \code{MPI_SEND}. 


% posting (async recv, posted before data arrives)
% - allocation of MPI req
% - buffers, datatypes
% - vc determination
% - calling method fn to post
% - is there anything really different from above (at this level)?

An asynchronous receive (\mpifunc{MPI_IRECV}) is handled in a similar manner.
A \code{MPI_Request} object is allocated and the completion counter is
initialized (also to 1).

The appropriate VC is determined by looking at the communicator passed to the
receive call.  From the VC object the appropriate method function for posting a
receive is found and called.
 
% progress 
% - what is the issue?  we want data movement.  it's acceptable to make progress
%   only when mpi calls are made.  we might want to use threads (just mention 
%   the opportunity)
% - progress engine - motivate why we need a component to do this
% - method functions called
% - datatypes, segments (packing and unpacking mentioned in passing?)
% - request matching going on too, mention relationship to vc data structures?
% - trust us, the request matching does need to be cross-method
% 
% [something here is still bugging brian]


Progress is simply the act of performing a set of operations necessary to
complete a pending request.  For example, a send request might require data to
be moved from memory to the network card so that it may be transmitted over the
network.
%
The MPI semantics allow for progress to only occur when MPI calls
are made; however, we might want to make progress at other times.  This could
be accomplished through the use of threads or other system capabilities (see
Section XXXX).

\begin{cmt}
  it would be great if there were clear definitions of ``requests'' and
  ``operations'' around somewhere.
\end{cmt}

In our multi-method P2P communication system a \term{progress engine} component
is responsible for orchestrating progress on all posted requests.  This is
necessary in order for the system as a whole to balance service across methods.
The progress engine invokes a method function, giving the method an opportunity
to make progress on pending requests (operations in progress?).  This method
function must utilize \term{buffer} information (user buffer location,
datatype, count) provide when the request was posted in order to determine the
appropriate data regions to send or receive.

Matching of requests occurs within the context of progress as well.  In our
example scenario, our receive was posted before any data from the sender
arrived.  The posted received is associated with the VC on which data will be
passed.  At some point that data does arrive, and the \term{envelope} from
the incoming message must be matched to the envelope from the posted receive.

\begin{cmt}
  define envelope?  point out that it should have been defined?  briefly
  mention a definition and then point at another section for details (are there
  any details???)
\end{cmt}

% completion
% - notification of completion (via decrement of counter - in MPI request)
% - note that a counter becomes important when we get to collectives, kinda
%   overkill for this.
% - deallocation of MPI request?  nope.  deallocated by wait/test instead.  
%   do we want to mention this here?
% 

Once all data has been copied out of the sender's buffer (either onto the wire
or into some other buffer), the send is considered complete from the
application point of view.  On the receive side things aren't complete until
all data has been received into the buffer supplied to \code{MPI_RECV}.
%
At this point the completion counter is decremented, and since it is now zero,
the request is considered complete.  The P2P communication system, however,
cannot deallocate the MPI request because this is still in use by the
application as a reference to the operation.
%
A \mpifunc{MPI_TEST} would indicate that
the request completed, and a \mpifunc{MPI_WAIT} could return.
%
When the \code{MPI_WAIT} is called, the request may be deallocated.
%
The use of a counter when the value may only be one or zero might seem
unnecessary, but we will see in Section~XXXX that having a counter is
necessary for our implementation of collective operations.

\begin{cmt}
  \code{MPI_TEST} and \code{MPI_WAIT} do the same thing on completion.  The
  above text needs a little cleanup to make that clear.
\end{cmt}

The components that we introduced here are described in greater detail in the
following section.

%------------------------------------------------------------------------------

\subsubsection{Interfaces, Objects and Components}

In this section we introduce a series of interfaces, objects and components
that are relevant to the multi-method architecture.  We begin by briefly
describing important objects defined by the MPI standard and how their
internals are affected by the multi-method device.  Then we define the
interface for a method, a key component to our architecture.  Finally, we talk
about the components that bind methods into the MPICH implementation.

% components needs to perform point-to-point communication:
% \begin{itemize}
% \item assumed knowledge stuff -- requests, communicators, datatypes,
%       segments, buffers, messages, envelopes
% \item virtual connections
% \item methods --
% interface to convey messages to be sent and received
% \item requst matching
% \item progress engine --
% only poll methods that might have work to do.  need a low cost way to
% communicate amount of work between method and progress engine.
% \end{itemize}
%
% talk about specific functions as they come up


%----------

\paragraph{MPI Communicators}

In MPI, a \term{communicator} is an object that represents a
\term{communication context} (or domain) and a group of processes that can
communicate within that context.  A handle to a communicator object is returned
by the MPI routines that create communicators.  In MPICH, a communicator handle
has a type of \code{MPI_Comm} while a communicator object has a type of
\code{MPID_Comm}.  A communicator handle may be converted to a communicator
object using \code{MPID_Comm_get_ptr}.

A communicator combined with a rank identifies a remote process.  Furthermore,
it must identify how to communicate with that process.  Within the multi-method
device, a communicator and rank map to a virtual connection, an object used to
track communication with a particular remote process.  The function
\code{MPID_Comm_get_VC} performs the mapping.  Virtual connections will be
discussed in detail shortly.

\begin{cmt}[BRT]
  This seems like a weak introduction to communicators, but I couldn't think of
  anything else to say.
\end{cmt}

\begin{verbatim}
int MPID_Comm_get_VC([IN] MPID_Comm * comm, [IN] int rank, [OUT] MPID_VC * vc)
\end{verbatim}

\begin{cmt}[BRT]
  Does returning a VC automatically bump its reference count?  It seems
  unnecessary for a correctly written MPI program, but I'm not certain of this.
  Do we even need a reference count on the VC before we introduce dynamic
  process creation and connect/accept?
\end{cmt}

\begin{cmt}[ROB]
  We decided that the VC refct can be bumped when the VC is first associated
  with a new communicator.  Decremented when a communicator is destroyed.
\end{cmt}

%----------

\paragraph{MPI Requests}

A MPI \term{request} is an object that identifies a communication operation
posted using one of the MPI non-blocking communication functions such as
\code{MPI_Isend} and \code{MPI_Irecv}.  These functions return a handle to a
request object describing the pending operation.  In MPICH, a request handle
has a type of \code{MPI_Request} while a request object has a type of
\code{MPID_Request}.  A request handle may be converted to a request object
using \code{MPID_Request_get_ptr}.

\begin{comment}
  Is this mapping of objects to types true for requests?  They appear to be
  treated differently that other MPI types in the design document.
\end{comment}

The MPI request object contains a completion counter that the multi-method
device must use to signal completion.  When the request is initialized, the
counter is set to the number of operations that must complete before the
request is considered complete.  The value of this count is controlled
entirely by the device.  The only meaning the MPICH layer assigns to this
counter is that a non-zero value indicates the request is still pending while
a value of zero shows the request is complete.  The methods have a consistent
means of using this value across implementations so that completion of
requests that span methods can be correctly detected as completed at the MPICH
layer.

%----------

\paragraph{MPI Datatypes}

In MPI, a \term{datatype} expresses the layout of a data structure.  A datatype
combined with a count and a memory location defines a \term{buffer} from which
data can be sent or into which data can be received.

In MPICH, a datatype handle has a type of \code{MPI_Datatype} while a datatype
object has a type of \code{MPID_Datatype}.  A datatype handle may be converted
to a datatype object using \code{MPID_Datatype_get_ptr}.  A buffer has no
direct representation in MPICH; however MPICH does introduce the notion of a
segment, which describes a portion of a buffer.  Segments are used in MPICH to
process a buffer in reasonably sized pieces and to maintain state on the
progress of processing.  A segment is respresent by an object tha has a type
of \code{MPID_Segment}.

%----------

\paragraph{MPI Status}

In MPI a \term{status} object is used to return information about the
completion of operations, including the source, tag, and count of received
messages.  In MPICH a status handle has the type \code{MPI_Status} while a
status object has the type \code{MPID_Status}.  A status handle may be
converted to a status object using \code{MPID_Status_get_ptr} (?).

\begin{comment}[ROB]
What else do we want to say about MPI Status?
\end{comment}

%----------

\paragraph{Method}

% method
% - implementation of an abstract interface mapping to a network device or API
% - examples:
%   - TCP
%   - VIA
%   - unbound
% - role of unbound method (optimization -- still include???)
%   - special case
%   - chooses a method for communicating with another process
% - functions:
%   - query/get_description() -- returns string describing local process 
%     capability and contact information for this particular method
%   - match_description() -- determines if the local process is able to
%     contact some other process described by a string passed to the
%     function...
%   - post a simple send
%   - post a simple receive
%   - poll -- progress opportunity; must provide feedback on
%     progress/completion
%     - there should be some ``time allowed to block'' abstract 
%       value that is passed into this function
%     - returns # of completions

To simplify multi-method communication in MPICH, we introduce a
\term{multi-method interface} to abstract away the details of any particular
network device or API.  In priciple, the method interface serves a similar
purpose to that of the MPICH device interface.  However, the method interface
further reduces the number of MPI structures crossing the interface boundary.
This simplifies the understanding of MPI required by the method implementor and
decreases the replication of code across the various methods.

The \term{communication method} (or more simply the ``method'') is a layer of
software that implements this multi-method interface for a particular
networking model, device or interface such as TCP, VIA or shared memory.

\begin{discussion}
  One might be tempted to think of a method as an object; however, we impose
  the limitation that only one instance of a particular method may exist in any
  given process.  This implies that all data associated with the method can be
  internally associated with that method and no pointer to the method is
  required by the method functions in order to access the data.
\end{discussion}

\begin{verbatim}
MPID_Method * MPID_Method_%M_init()

int method::finalize()

void method::get_description([OUT] char description[])

void method::match_description([IN] char description[], [INOUT] MPID_VC * vc,
        [OUT] bool matched)

void method::post_send(
        [IN] MPID_Segment * segment, [IN] MPID_VC * vc, [IN] MPID_Comm * comm,
        [IN] int dest, [IN] int tag, [INOUT] int * completion_cntr,
        [INOUT] MPID_Status * status)

void method::post_recv(
        [IN] MPID_Segment * segment, [IN] MPID_VC * vc, [IN] MPID_Comm * comm,
        [IN] int source, [IN] int tag, [INOUT] int * completion_cntr,
        [INOUT] MPID_Status * status)

bool method::poll([IN] int quanta)
\end{verbatim}

\begin{cmt}[BRT]
Should we put the function table in a \LaTeX table or leave it as is?
\end{cmt}

\begin{cmt}[BRT]
  Do we want to say anything about initialization here?  In general we are
  deferring the discussion on initialization until the next subsection, but
  should we at least introduce the routines?
\end{cmt}

Since several methods of communication are likely to be at the disposal of a
process, we need a mechanism for resolving which method will be used for
communicating between a particular pair of processes.  This mechanism should
include utilizing user supplied information that dictates the method to be used
for each process pair; however, it is desirable to automate the selection of
communication methods when the user chooses not to supply the necessary
information.  Therefore, we need a mechanism whereby a remote process can
describe its communication capabilities in such a way that the local process
can programmatically determine the method it will use to communicate with a
remote process.

Rather than attempt to create a capability description language that can be
understood by a method independent routine, we chose to push all understanding
of the description into the method.  We prove two functions to satisfy the
above state requirements.  The first function, \code{method::get_description},
returns a string encoding of both the capability description and any associated
contact information.  By looping across the methods, a collection of these
description strings can be constructed, the result of which describes the set
of communication capabilities and contact information for the process.  This
collection can then be published into a database available to all processes in
the job, making the capabilities and contact information known to all
processes.  This database functionality is provided as part of the BNR
interface, which is described in Section~\ref{sec:bnr}.

Given a collection of descriptions for a remote process, the local process can
now select a method.  The capability description string for a particular method
is passed to the \code{method::match_description} function, which is
responsible for determining if it is capable of communicating with the remote
process using the method in question.  If the processes are capable of
communicating using that method, \code{match_description} extracts the contact
information from the description string and stores it for later use.

The method selection policy is implemented by code{MPID_VC_get_method}.  This
function determines the order in which the \code{method::match_description}
functions are called and thus ultimately the priority of the methods.  We will
discuss the \code{MPID_VC_get_method} function more when we talk about virtual
connections.

Now that we have defined an interface supporting the selection of a method, we
must introduce an interface for communicating messages using that method.  We
have decided on a non-blocking interface that permits send and receive
operations to be posted to the method, allowing the method to complete those
operations as resources permit without halting the progress of the calling
routine.  Send and receive operations are posted by calling the
\code{method::post_send} and \code{method::post_recv} functions respectively.
As these are non-blocking functions, they are primarily responsible for
recording the requested operation, although they are permitted to initiate the
operation if the state of the method and connection permit doing so
immediately.

Once requests have been posted, we need a mechanism to make progress on them.
One option is to have one or more threads responsible for sending and receiving
data.  Hoever, the overhead of context switching between those threads is
fairly high, especially when compared to the latencies typically of high
performance networking resources.  Therefore, while the use of threads may be
acceptible for some methods, we need to provide a low overhead means of polling
in order to make progress on outstanding requests.

The \code{method::poll} function is the mechanism for providing the method will
an opportunity to make progress.  We envision this method being called by the
progress engine which we will describe shortly.  The \code{poll} function takes
a single argument, \code{quanta}, that conveys the amount of time the function
is allowed to block waiting for an event.  This argument should be viewed as a
soft upper bound used to impose a rough schedule between the methods.  It is
intended to limit non-productive blocking or busy waiting only and should not
be viewed as a limit on the amount of useful work that can be completed by the
method.  A method may choose to ignore the argument and return immediately if
it has no work to perform.  Likewise, if the method has work to perform it
should do so without worry about exceeding the limits expressed by the
\code{quanta} argument.

The reason for expressing time in quanta rather than realtime is twofold.
First, we were attempting to dispell the notion that it was necessary to
``watch the clock'' which on many systems can be a very expensive operation.
Second, we believed that having an integer value instead of a timeval structure
would simplify the computation required in critical path components.  We expect
that, at startup, methods wishing to utilize the \code{quanta} argument will
measure the busy waiting algorithm used in their \code{poll} functions to
establish an estimated number of loops per quanta.  Then a quick multiplication
can be performed when \code{poll} is called to determine the number of loops
that may be performed before the \code{poll} function must return control to
the progress engine.

\begin{discussion}
  The rationale for using a quanta is to allow \code{select()} in the TCP
  method to block for periods of time to avoid chewing up the CPU
  unnecessarily.  It may also be useful to obtain tighter busy waiting loops in
  methods like shared memory when the polling engine knows that no other method
  needs to be serviced for a while.  Some experimentation is necessary to
  verify that the \code{quanta} argument is really useful.
\end{discussion}

The \code{method::poll} function returns a boolean value indicating if any
completions since the previous call to the \code{method::poll}.  By providing
this boolean value, we allow the calling routine to avoid expensive progress
checking operations when no progress has been made.  For performance reasons,
this boolean is provide as a return value rather than as a outgoing argument.
A return value can often be transported between the callee and the caller using
a register, whereas an outgoing argument requires the use of memory operations.

It should be noted that, unlike most of the functions in MPICH, the
\code{method::poll} function does not return an error code.  After careful
thought, we realized that the calling routines, those providing an opportunity
to make progress, would most likely be unable to react to any errors that might
be reported to them.  It seemed far more appropriate for any errors that occur
during polling to be attributed to the operations in progress.  Such
attribution should be handled by having \code{method::poll} update the status
structures associated with those operations.  In some circumstances,
\code{method::poll} may also need to store error state within the method if the
error affects the proper completion of operations which might be posted in the
future.

\begin{discussion}
Initially, \code{poll} included a \code{completions} argument that returned the
number of MPI requests that were completed during the call.  The purpose of
returning this count was to allow the progress engine to provide feedback to
calling routines such as \code{MPI_TEST} and \code{MPI_WAIT} so that they could
limit the amount of work involved in determining which requests have been
satisfied and need to be deallocated.  We eliminated this argument when we
realized that the count was inexact in the face of multiple application threads
and asynchronous completion of requests.
\end{discussion}

As operations complete, the method provides feedback using the status object
and completion counter supplied when the operation was posted.  The error field
in \code{status} object is used to communicate any errors that occurred while
performing the operation.  For receive operations, the \code{status} object
will also contain information about the envelope of the message and the amount
of data received.  After the status object is updated, the completion counter,
\code{completion_cntr}, is decremented to indicate that the operation has
completed.

%----------

\paragraph{Virtual Connections}

% virtual connections
% - object representing an abstract connection between two processes
% - (communicator, rank) is used to resolve to a virtual connection 
%   (unidirectional mapping)
% - binding/selection of method
% - points to a method
% - concept of ``unbound'' method (which does the binding) as mechanism for 
%   binding
% 
% (steal some text from agent.tex)
% 
% - state machine diagram
% - functions (methods):
%   - MPID_VC_get_method
%   - MPID_VC_set_method ???
% - elements:
%   - send queue
%   - posted receive structure (maybe a list of queues?)

In MPI, the application expresses the desire to communicate with particular
remote process by specifying a communicator and a rank.  The MPI implementation
is responsible for mapping these (communicator, rank) tuples to some underlying
set of network resources and performing the communication using those
resources.  To minimize startup time and avoid unnecessary resource
consumption, it is desirable for the multi-method implementation to defer
binding to specific network resoures until those resources are needed.  To
faciliate late binding, we introduce the \term{virtual connection} object.

The virtual connection object, or VC, represents an abstract connection between
two processes.  To communicate, the VC must be bound to a communication method
which understands how to form a real connection and pass messages between the
two processes associated with the VC.  The process of binding to a method is
part of the \mpidfunc{MPID_VC_get_method} function, which selects an
appropriate method for the VC when it detects that the VC is in the unbound
state.  Once a VC is bound to a method, that binding persists for the remainder
of the programs exectution.

\begin{implnote}
  For performance reasons, it may make sense to cache the method function table
  in the VC object.  This would avoid an extra lookup each time a communication
  operation needed to be performed.  The downside is that an ``unbound'' method
  would need to be introduced which would contain a set of binding functions in
  its function table.  These functions would be responsible for binding the VC
  to a chosen method and then calling the equivalent function in that method's
  function table.
\end{implnote}

The virtual connection object is also used to house any per connection data
structures needed by the method, or what we refer to as \term{method specific
  data}.  These data structures include those necessary to track posted send
and receive operations, and the state of the underlying connection.  While the
size of the method specific data may vary with the method, the size of the VC
object is established at initialization time by calling
\code{method::get_vc_data_size} for each of the methods and using the maximum
value.  This may result in some wasted space, but it simplies allocation and
binding.  It also results in the method specific data being colocated with the
VC information, improving cached performance.

\begin{cmt}[BRT]
  I did not include the original state machine diagram as it became clear that
  the VC object was not responsible for establishing connections as the
  original diagram depicted.  The states for the VC object itself have been
  reduced to unbound and bound.  Connection establishment state should be part
  of the method specific data.
\end{cmt}

\Q Should we include a statement about the VC not being responsible for forming
any underlying connections?  Then we could get rid of the above comment.

%----------

\paragraph{Progress Engine}

% progress engine
% - choses methods which will be given the opportunity to make progress and 
%   gives them that opportunity by calling their poll function
% - functions:
%   - make_progress() -- determines who to call and how long they can work;
%     needs to know (via input parameter) if allowed to block
%     - returns # of completions

As discussed earlier, each of the methods must be routinely given the
opportunity to make progress.  This is accomplished by calling the method's
\code{poll} function.  In theory, this could be accomplished by looping over
all of the methods, calling each of their \code{poll} functions anytime an
opportunity existed to make progress.  In practice, however, this would prove
to be inefficient and result in poor communication performance.  Rather, we
introduce a \term{progress engine} component which implements a polling policy.
The progress engine is responsible for presenting the methods with an
opportunity to make progress on a schedule that accounts for issues such as
communication performance and method workload.  By having a separate component
and a well defined interface, optimizations can more easily evolve over time.

\begin{verbatim}
init MPID_PE_init()

init MPID_PE_finalize()

void MPID_PE_poll_blocking_init()

void MPID_PE_poll_blocking_start()

void MPID_PE_poll_nonblocking()
\end{verbatim}

\todo Describe \code{MPID_PE_init}.  This section should talk about how the
progress engine finds the methods and calls various method accessor functions
to gather information.  This information is used to decide who should be
polled.

Progress is be made by calling one of two sets of functions: blocking and
nonblocking.  The nonblocking set consists of a single function
\code{MPID_poll_nonblocking}.  In the blocking case, we need to worry more
about atomicity since we don't want the progress engine blocking if the
request we are waiting was satisfied between the time we check for completion
and the point at which we call the
blocking polling function.  

\todo [BRT] rewrite the above paragraph and elaborate on the need for a pair
of blocking functions.  how much do we want to talk about asynchronous 

\todo talk about the progress engine not needing any information about the
operations that the calling routines are waiting for; we believe that
prioritizing progress oppportunities based on knowledge about the requests that
we are blocking on would incur more overhead that it would provide benefit


% For the time being, the progress engine has a single function,
% \code{MPID_Make_progress}, which is called by the MPICH anytime an
% opportunity exists to make progress on communication.  This function is
% responsible for implementing the polling schedule discussed in the previous
% paragraph.  The \code{blocking} argument supplied to
% \code{MPID_Make_progress} indicates if the function is allowed to block (not
% return) until a completion counter associated with one or more of hte
% outstanding requests reaches zero.  The \code{completions} argument is used
% to return the number of operation
% 
% \begin{cmt}
%   For a single threaded implementation that does not make use of signals or
%   interrupts for processing communication, \code{MPID_Make_progress} is
%   sufficient.  However, if it is possible for operations to complete and for
%   that completion to be reflected in the completion counter outside of calls
%   to \code{MPID_Make_progress}, then we need to worry about the checking for
%   completions and calling of \code{MPID_Make_progress} being atomic with
%   respect to any completion counter updates.
% \end{cmt}

%------------------------------------------------------------------------------

\subsubsection{Walkthrough}
\label{sssec:walkthrough}

% - lay out a scenario (same as above, more detailed)
%   - there are lots of scenarios in another part of the document

Now that we have introduced the components involved in sending and receiving
messages, we will revisit the simple send-receive scenerio we discussed at the
beginning of this section.  This time, we discuss the control flow and data
movement in more detail, explicitly listing the components and functions
involved.

% - posting
%   - getting the request (MPID thing)
%   - getting the vc
%   - getting the method from vc
%   - method binding
%   - forming connections (TCP)

To post a send request, the application code calls \mpifunc{MPI_ISEND} which in
turn calls \mpidfunc{MPID_Isend}, the device-level function responsible for
responsible for initiating a send.  \code{MPID_Isend} begins by allocating the
\mpiobj{MPI_Request} object using \mpidfunc{MPID_Request_alloc}.  Next, the
request completion counter, \mpids{MPI_Request}{ccnt}, is set to one indicating
that a single operation is outstanding.  Once the request structure is
initialized, the communicator and destination rank supplied by the application
are passed to \mpidfunc{MPID_Comm_get_vc} to obtain the associated virtual
connection object.

\begin{cmt}
  We need a name for ``a unit of work for a method''.  We're using
  ``operation'' here, but that is really too generic/overloaded.  We should
  make up an acronym, like CAR, but different :).
\end{cmt}

As mentioned earlier, the virtual connection object allows us to defer
selecting a method of communication until the connection will be used.  The
method object bound to the VC is obtained by calling
\mpidfunc{MPID_VC_get_method}.  If this first time the VC has been referenced,
the VC will be in the unbound state, meaning that it is presently not
associated with any method.  In this case, \code{MPID_VC_get_method} will
select select an appropriate communication method and bind it to the VC.

\begin{cmt}
  An interesting artifact of not caching the method function table in the
  virtual connection object is that we no longer need the ``unbound'' method.
  Instead, \code{MPID_VC_get_method} becomes solely responsible for binding to
  a method should the VC not already be bound.  This seems much cleaner, at
  least from a design perspective.
\end{cmt}

Once we have both the method and virtual connection objects, we can use the
\code{method::post_send} function to post a send operation on the VC.  This
method specific function is responsible for insuring that the message is sent
according to MPI messaging semantics.  To help accomplish this task, the VC has
space for method specific data, which \code{post_send} can use to track
outstanding posted messaging requests.

In an attempt to be more specific, we shall look at one possible
implementation of the \code{post_send} function for the TCP method.  In the TCP
method, socket connections are only formed between processes when it becomes
necessary for those processes to communicate.  This implies that a socket
connection may not exist for a particular virtual connection when
\code{post_send} is called, and that \code{post_send} may need to form such a
connection before it can begin sending data.  Assuming a socket connection has
been formed, the \code{post_send} function can begin sending data to the remote
process immediately if no other outgoing messaging requests are enqueued on the
VC.  If other requests are present, then \code{post_send} will need to enqueue
the request and let the progress engine handle sending the message once
previous requests have been satisfied.

To post a receive request, the application calls \mpifunc{MPI_IRECV} which in
turn calls \mpidfunc{MPID_Irecv}.  \code{MPID_Irecv} is the device-level
function responsible for posting receive requests to the appropriate method.
For the moment, we are ignoring receive requests posted with a source of
\code{MPI_ANY_SOURCE}, or what are frequently referred to as ``wildcard
receives''.  Wildcard receives present an interesting set of challenges for a
multi-method device and will be discussed in Section~\ref{FOO}.

Like \code{MPID_Isend}, \code{MPID_Irecv} must resolve the (communicator, rank)
tuple to a virutal connection and obtain a reference to the method associated
with that virtual connection.  All of the previous discussion concerning the
binding of a VC to a method applies here as well.

The ordering of an incoming message with the posting of a matching request
presents two possible execution paths.  An incoming message may arrive before
or after the posting of a matching receive request.  We determine this ordering
for a particular request by having \code{MPID_Irecv} call
\code{MPID_Recv_post_foa} (foa stands for ``find or allocate'').
\code{MPID_Recv_post_foa} either finds an already arrived message that matches
the envelope supplied to \code{MPI_Irecv} and returns an associated existing
request, or it returns a new request object which has been atomically added to
the (publically accessible) receive list located in the VC.

\begin{cmt}
  The use of request within the device is getting confusing.  We may need to
  introduce multi-method requests now in order to avoid confusing the reader
  later (or now for that matter).
\end{cmt}

% \todo{need to talk about \code{method::post_recv}}

% - progress
%   - where/when make_progress() is called
%   - deciding when a method's poll function is called (don't call if there 
%     are no outstanding operations)
%     - what is the interface for figuring out how many operations are 
%       outstanding? -- values in method elements
%   - send and receive state machines
%     - simplify -- cut out the flow control, buffer mgmt., optimizations

\todo{talk about progress}

% - completion
%   - completion reported from method
%   - decrementing counters
%   - when requests are finally freed
%     - interface!  -- should be an MPID thing...

\todo{talk about completion}

%------------------------------------------------------------------------------

\subsubsection{Summary}

% - what did we just talk about? -- state of the design
%   - recap the capabilities at this point
%   - recap the components we have developed
% - tables describing interfaces (?)
% - lead into next subsection (add some new capabilities)

%==============================================================================

\subsection{Method initialization and management}

This section will talk about how methods are initialized and managed.

This discussion will begin with an environment where all methods are
statically bound to the executable.

\begin{verbatim}
MPID_Method * MPID_Method_%M_init()
\end{verbatim}

Then, we will discuss how method management changes if dynamic
loading of methods is allowed.

\begin{verbatim}
MPID_Method * MPID_Method_init()
\end{verbatim}

%==============================================================================

\subsection{Filling out point-to-point}

\subsubsection{Wildcard Receives}
\begin{itemize}
  \item request matching as a cross-method component (see, we told you!)
  \item request abritrator element - secret magic wildcard stuff
\end{itemize}

\paragraph{Communication Action Requests}

\paragraph{Request Arbiter}

% request arbiter
% - performs matching between posted requests and incoming messages, handling 
%   specifics of mpi semantics for matching and ordering
% - global unexpected queue (not needed yet, but we keep it for later)
% - walks posted receive structure for appropriate VC first
% - not worrying about wildcards yet
% - functions:
%   - recv_posted_foa() -- allocate a new recv request and post it to the VC 
%     unless the request already exists in the unexpected list
%   - recv_incoming_foa() -- search the VC posted recv structure for a request
%     that matches the supplied envelope information; if one is not find
%     allocate a new request and place it on the ordered unexpected list
% - elements:
%   - ordered unexpected list
%
% - requirement that certain structures be publically visible (e.g. receive 
%   lists)

This matching process might seem trivial, but in fact the MPI semantics for
wildcard operations and message ordering combined with the possibility of
multiple methods make matching somewhat complicated.
For this reason we will implement a separate \term{request arbiter}
component for performing request matching for the
system as a whole (both intra- and inter-method).

\begin{verbatim}
int MPID_RA_post_foa(
        [IN] int dest, [IN] int tag, [IN] MPID_Comm * comm, [IN] MPID_VC * vc,
        [OUT] MPID_CAR * car, [OUT] int * found)

int MPID_RA_incoming_foa(
        [IN] int dest, [IN] int tag, [IN] MPID_Comm * comm, [IN] MPID_VC * vc,
        [OUT] MPID_CAR * car, [OUT] int * found)
\end{verbatim}

\begin{cmt}[BRT]
  We need to define multi-method requests before we can describe request
  arbitration since the requests store in the receive lists are multi-method
  requests.
\end{cmt}

\code{recv_posted_foa} returns a locked CAR to insure atomicity; the calling
code must unlock the CAR

\subsubsection{Persistent Sends}

\subsubsection{Request Cancellation}

\begin{cmt}
  Message cancellation is considered a local operation (not requiring the
  remote process to call any MPI functions).  Does this imply that active
  messages are needed for message cancellation?  If so, this discusssion needs
  to wait until active messages are introduced.
\end{cmt}

%==============================================================================

\subsection{Threads: implementation and usage}

\paragraph{Method binding} threads, VCs, and changing methods (from unbound
to bound) during runtime
\begin{itemize}
\item having the unbound method hold a lock on the vc can prevent additional
  threads from also attempting to rebind the VC
\item the newly bound method may receive requests from other threads while it
  is forming a connection.  it must insure that requests are queued and handled
  in the proper order once this connection is established
\end{itemize}

\paragraph{Request arbiter} The request matching process becomes much more
complex when multiple threads are introduced.  The arbiter and method must work
together to insure that incoming unexpected message CARs and posted receive
CARs do not bypass each other causing a match to be missed and MPI message
ordering semantics to be violated.  We believe this coordination can happen
relative efficiently using some sort of two phase posting interface between the
RA and the method.

This two phase posting interface would consist of the functions
\code{method::post_recv_init} and \code{method::post_recv_start}.  The first
function would insure that the method did not attempt to post unexpected
messages with the RA until after the second the function was called.  During
the period of time between the calls to the first and second functions, the RA
could safely scan the unexpected message list for matching messages without
concern that a matching unexpected message might be posted after its scan of
the unexpected list but before the CAR could be posted with the method.

\paragraph{Polling} The semantics of \code{method::poll} must be modified
slightly.  The boolean return value should express whether or not any
completions have occurred since poll was last called the current thread.

\paragraph{Progress Engine} The registration function needs to be augmented so
that it know if completions may occur asynchronously.  This is not strictly an
issues that arises with threads.  It is also an issue of the completion
counters are capable of being updated remotely (ex: shared memory or LAPI).

%==============================================================================

\subsection{Vendor MPI}

Discuss the enhancements required to support vendor MPI as a method for
point-to-point communication.
\begin{itemize}
\item datatypes
  \begin{itemize}
  \item to track the construction, destruction and committing of datatypes so
    that the process can be duplicated in an underlying vendor MPI
  \item need method specific space in datatype object 
  \end{itemize}
\item communicators
  \begin{itemize}
  \item track the creation (and destruction) of intra- and inter-communicators
    so that they can be duplicated in the underlying vendor MPI
  \item need method specific space in communicator object 
  \end{itemize}
\item groups
  \begin{itemize}
  \item it may be desirable to track groups much like communicators
  \end{itemize}
\end{itemize}

%==============================================================================

\subsection{Optimizing Simple Messaging}

% [BRT] To what degree do we want to discuss optimizations of simple
% messaging?  It seems like most of these optimizations apply to any
% device, not just the multi-method device.  On the other hand, we do
% want to support these optimizations, so it seems unwise not to mention
% them and include them in the design.

\subsubsection{bypassing the request arbiter}

In the common case of pre-posted, non-wildcard receives, we would like to avoid
interacting with the arbiter at the time of message reception.  We accomplish
this by extending the request arbiter's post_foa() function to notify the
method of posted requests under circumstances where inter-method arbitration is
not required.  The incoming message matching is then handled directly by the
method without further interaction with the RA.  (That is to say that the
method will first check its internal list of posted receives before calling
incoming_foa().)  This has the additional benefit of allowing the method to
optimize reception by allowing it to know of the recv call ahead of time (which
it did not earlier in this document).

\begin{verbatim}
post_foa()
    look at unexpected list(s)
    if existing request not found
        look at posted wildcard list(s)
        if no request in same context (or other optimized conditions)
            method::post_recv(...)
\end{verbatim}


\subsubsection{more optimizations}

for contiguous data, send directly from and receive directly into the
user buffer.

packing and unpacking, segments, datatypes...

receiving a message by reading it directly from the memory of the
sending process (e.g., ptrace and /proc/PID/mem) or sending a message
by writing it directly to the memory of the receiving process.

allow the user to \mpifunc{MPI_ALLOC_MEM} to allocate a buffer in shared
memory, reducing the number of data from two to one when using the
shared memory method.

special blocking send/recv optimizations?

\paragraph{Progress Engine} adaptive polling and such
\begin{itemize}
\item methods have elements that hold progress information
\item progress engine looks at these elements when making decisions
\item uses knowledge of outstanding request counts, recent traffic, etc. to
  prioritize methods and compute polling schedules
\item does not need to know which specific MPI requests are being waited
  on, only that one or more is outstanding for a particular method
\end{itemize}
  
\todo Talk about information needed from method.  Most of the information
needed from the the method is for optimizations such as ``skip polling'' and
``adaptive skip polling''.  Discuss the need for high-performance and the use
of method data to convey information rather than accessor functions.

\todo talk about policy for deciding when to quit polling and return from
blocking and non-blocking routines.

\todo talk about fairness issues - making sure that the first method doesn't
receive an unfair amount of polling cycles just because it is the first method
in a list

\todo Add discussion about need for \code{method:poll_sync()}.  This routine
can be used to reset internal method state so that \code{method::poll} only
returns true if any completions have occurred since the last call to
\code{method::poll} or \code{method::poll_sync}.  This optimization should
significantly reduce false positives, which do not affect correctness but will
likely increase polling overhead and thus latency.

%==============================================================================

\subsection{Support for Collective Operations}

\begin{itemize}
\item recv-and-forward messaging operation to support pipelining
  \begin{itemize}
  \item concurrency (rules)
  \item progress notification (rules)
  \item inter-method buffer management
  \end{itemize}
\item requests and descriptors
\item new method functions
\end{itemize}

%==============================================================================

\subsection{Advanced Collective Operations}

\begin{itemize}
\item multi-forward to support pipelined tree-based algorithms
\item reduction operations
\item buffer management revisited (for what purpose???)
\end{itemize}

%==============================================================================

\subsection{Abnormal Termination}

MPI_Abort() introduces the need for active messages in order to support clean
and timely termination

%==============================================================================

\subsection{RMA}

%==============================================================================

\subsection{Advanced RMA}

%==============================================================================

\subsection{Connect and Attach}

%==============================================================================
