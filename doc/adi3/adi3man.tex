% 
%   This is a latex file that generates a reference manual for 
%   ADI-3 
%
\documentclass{article}
\usepackage{/home/gropp/data/share/refman}
\usepackage{/home/gropp/sowing-proj/sowing/docs/doctext/tpage}
\usepackage{epsf}
\textheight=9in
\textwidth=6.1in
\oddsidemargin=.2in
\topmargin=-.50in
\newread\testfile

%
% Modify the way titles are handled for no breaks between pages
\def\mantitle#1#2#3{\pagerule\nobreak
\ifmancontents\addcontentsline{toc}{subsection}{#1}\fi}

\begin{document}

\markright{ADI-3 Reference Manual}

\def\nopound{\catcode`\#=13}
{\nopound\gdef#{{\tt \char`\#}}}
\catcode`\_=13
\def_{{\tt \char`\_}}
\catcode`\_=11
\def\code#1{{\tt #1}}

%\tpageoneskip
\ANLTMTitle{MPICH Abstract Device Interface\\
Version 3\\
Reference Manual\\\ \\Draft}{\em 
William Gropp\\
Ewing Lusk\\
Mathematics and Computer Science Division\\
Argonne National Laboratory}{00}{\today}

\clearpage

\pagenumbering{roman}
\tableofcontents
\clearpage

\pagenumbering{arabic}
\pagestyle{headings}

\section{Introduction}
This document contains detailed documentation on the routines that are part of
the Abstract Device Interface, version 3, used to implement the MPICH2000
model MPI implementation. 

% As an alternate to this manual, the reader should consider using the
% script \code{mpiman}; this is a script that uses \code{xman} to provide
% a X11 Window System interface to the data in this manual.

\section{Discussion}
The ADI contains a large number of routines, but only a few of these
are related to the lowest-level communication operations.  Most of the
rest are used to provide opportunities for performance optimization
(e.g., \code{MPID_Isend}) or to support the objects that MPI
provides and that a device implementation may (or may not) need to
understand (e.g., MPI attributes and groups).  

The ADI is organized as a number of separate modules.
For each module except for the core communication module (called MPID
CORE), there is a sample (but complete) implementation.  These sample
implementations are refered to as the \emph{generic} module
implementations. For example,
the ADI contains routines to create and manipulate MPI communicators;
most implementations of the ADI will use the generic module for
handling communicators.  Other modules, such as the point-to-point
communications module, are more likely to be replaced with a
device-specific implementation.  Even in the cases where an
implementation of the ADI replaces a module, the generic
implementation of that module will often serve as a guide.

There are roughly three classes of modules:
\begin{enumerate}
\item The core: basic process creation and communication. This
contains one module, MPID CORE. 
\item Support for MPI objects.  These modules support the various MPI
objects such as Datatypes, Groups, Communicators, and keyvals.
\item Communication optimization.  These modules provide an
intermediate level of functionality between that provided by MPID CORE
and that provided by MPI.  The rationale for these are described in
Section~\ref{sec-intermediate}. 
\end{enumerate}

The modules are (THIS LIST IS INCOMPLETE):
\begin{description}
\item[MPID CORE]. Basic functions to start, stop, and communicate
between processes.  This also includes the \code{mpiexec} program.
This is the only module for which there is no generic implementation; as
described in Section~\ref{sec-minimal}, implementing just this module,
combined with the generic implementation of the other modules, provides a
complete ADI-3 implementation.
\item[Attribute]. MPI Keyvals and attributes
\item[Datatype]. MPI Datatypes and pack/unpack operations and a new
object, \code{MPID_Segment}, used only within the ADI.
\item[Dynamic]. Support for MPI-2 dynamic process operations.  This
module must be implemented to support the dynamic process chapter of MPI-2.
\item[Group]. MPI Groups
\item[Communicator]. MPI Communicators
\item[Request]. MPI Requests.  Requests are fundemental to many
operations; most devices that implement more than MPID CORE will need
to replace this module.
\item[Window]. MPI Windows.
\item[Point to point]Functions directly implementing the MPI
point-to-point communication functions or some key subsets.
\item[Topology].Information on the physical interconnect.  Currently
limited to hierarchical information necessary to support clusters of
SMPs and similar systems.
\item[Timer]. Support for fast timers, including synchronized timers.
\item[Stream]. Communication routines designed to support
important algorithms for collective communication.
\item[Collective]. Alternate support for collective
routines. \textbf{Note that this may end up being an MPI module, not
an MPID module.}
\item[Utility]. Routines to simplify correctness and performance
debugging, and to provide a common interface to OS services that have
different interfaces on different platforms.
\item[Environment]. This module contains both compile-time and run-time
constants that describe the environment. 
\item[Communication]. The routines that carry out communication among MPI
  processes. 
\item[Error Reporting]. This provides support for detailed error
reporting.  Most implementations will use the generic implementation
of this module.
\item[Extensions]. This module contains no required routines; instead,
it documents some of the various extensions that the MPICH group is
considering, such as checkpointing.
\end{description}

By dividing the ADI into these modules, it becomes easy to implement
MPI quickly by implementing just MPID CORE and using the generic
modules for everything else.  Other modules can be replaced as
warranted; for example, a new machine will likely need a new Timers
module in order to access a system-specific timer.  Implementors
trying to get the maximum performance for point-to-point operations
may want to replace that module with one carefully tuned to their
specific platform.

Not included in this list is the ADIO module used to support MPI-IO.
See \cite{romio-adio-manual} for a description of that module.

\subsection{The Core}
\label{sec-minimal}

While ADI-3 defines a large number of routines, only a few must be implemented
by a developer.  For all modules except the \code{MPID_CORE} module, MPICH
provides a generic implementation.  Thus, only the routines in
\code{MPID_CORE} must be implemented when porting MPICH to a new interprocess
communication mechanism.  \code{MPID_CORE} consists of the following routines: 

\begin{description}
\item[\code{MPID_Init_thread}]. This is the device's counterpart to
\code{MPI_Init_thread}. 
\item[\code{MPID_Finalize}]. This is the devices's counterpart to
\code{MPI_Finalize}
\item[\code{MPID_Abort}]. This is the device's counterpart to \code{MPI_Abort}.
\item[\code{MPID_Put_contig}]. This is used for data movement; it is roughly an
\code{MPI_Put} using only contiguous data.  However, it uses a
different mechanism for indicating completion of data transfers (see \code{MPID_Flags_waitsome} and \code{MPID_Flags_testsome})
\item[\code{MPID_Rhcv}]. This is used for messages; it is roughly an
active-message call.  However, only predefined actions are allowed,
and these actions are enumerated.
\item[\code{MPID_Flags_waitsome}, \code{MPID_Flags_testsome}]. These
are used to complete \code{MPID_Rhcv} 
and \code{MPID_Put_contig} operations
\item[\code{MPID_Poll}]. This routine provides a way for a polling routine to
be called.  A device is permitted to define this as a no-op if polling
is not needed.  In other words, this routine is provided to
\emph{allow} polling implementations, not to \emph{require} them.
\item[\code{mpiexec}]. An implementation of \code{mpiexec}, as defined in the
  MPI-2 standard, for starting MPI jobs.  While not a routine, it must be 
  provided by any device.  
\end{description}
From these routines, together with the implementation of MPI in terms of MPID
that we are planning to carry out, all of MPI can be implemented\footnote{See
Section~\ref{sec-passive-target} for some caveats about pure polling
implementations}.  However, this approach may sacrifice performance
for simplicity.  For increased performance, one might want to do direct
implementations of some of the non-core MPID routines, such as
\code{MPID_Isend}, directly, without relying on core routines.  For example, a
shared-memory implementation might want to rely on \code{memcpy} directly
instead of \code{MPID_Rhcv}.

This is not the only small set of routines from which MPI can be
implemented.  However, the one-sided operations defined in MPI-2 make
it difficult to use a two-sided (message-passing-like) core.
Alternately, \code{MPID_Put} isn't actually necessary; the same
functionality is provided by \code{MPID_Rhcv}.  However, experience
with active messages, as well as current trends in interconnects,
suggests that a remote memory put operation that does not require any
other processing at the target (destination) should be separated from
the more general active-message invocation (\code{MPID_Rhcv}).

\subsection{Dynamic}
For a full MPI-2 implementation, the dynamic module must also be
implemented.  That is, for a full MPI-2 implementation, the dynamic
module is really part of \code{MPID_CORE}.  This module is separated
out both because it is unnecessary for MPI-1 and because the
implementation of these routines is (usually) very different from the
communication support in \code{MPID_CORE}.  The contents of the
dynamic module include:

\begin{description}
\item[\code{MPID_Comm_Spawn_Multiple}]. Spawns new processes.  An
implementation 
  that does not plan to support \code{MPI_Comm_spawn} or
  \code{MPI_Comm_spawn_multiple} can implement these as routines that return
  failure.  Such an implementation will not implement all of MPI-2.
\item[\code{MPID_Open_port}]. Open a port for connecting to processes.  The
  routines \code{MPID_Open_port}, \code{MPID_Close_port},
  \code{MPID_Comm_connect}, \code{MPID_Comm_attach}, and
  \code{MPID_Comm_disconnect} can be considered a 
  ``submodule'' supporting the corresponding part of the MPI-2 standard.  Just
  as for \code{MPID_Comm_spawn_multiple}, an implementation that chooses to
  support only the subset of MPI-2 that does not include the MPI routines for
  connecting two groups of MPI processes may implement these routines by
  simply having them return failure.
\item[\code{MPID_Close_port}]. Close a port opened with \code{MPID_Open_port}.
\item[\code{MPID_Comm_connect}]. Connect to an MPI program.
\item[\code{MPID_Comm_attach}]. Attach to an MPI program.
\item[\code{MPID_Comm_disconnect}]. Detach from an MPI program.
\end{description}

\subsection{Design Rationale}
\label{sec-intermediate}
The design of MPI puts a number of constraints on a high-quality
implementation.  These constraints help explain the rationale behind
the design of ADI-3.

We start with a few general principles.  The first is that all valid
MPI programs should work.  This implies that implementations should
maintain proper flow control and should strive not to allocate new
memory after \code{MPI_Init_thread}.  It certainly should not require
the allocatation of memory proportional to the size of a message.
This simple rule has significant consequences, starting with the
handling of datatypes.

\subsubsection{Noncontiguous Datatypes}
Any message in MPI may be defined by a datatype representing
non-contiguous locations in memory; there is no limit (other than the
usual limits of available memory) on the size of this message.  Since
no interconnects provide a way to send arbitrarily large
non-contiguous messages (and even in shared memory, the complexity of
handling the layouts of both the sending and receiving datatypes), an
ADI must provide a way to pack and unpack datatypes to and from
contiguous buffers.  
Further, because the message may be arbitrarily large, an internal
buffer,
used only to hold a contiguous form of the message, should
not be allocated for the entire message.
The consequence of this rule is the \code{MPID_Segment} object and the
routines to perform partial pack and unpack operations.

A less obvious consequence of the need to handle noncontiguous
datatypes in pieces (or segments) is that an ADI interface that
provides MPI-like point-to-point operations, but only for contiguous
data, cannot be used without significant modification.  

\textbf{To see what the modifications would look like, see the old RMQ design that I did; it used
handlers within the ack-loop.} 

\subsubsection{Passive Target RMA}
\label{sec-passive-target}
\textbf{text describing passive targets as requiring a non-polling
interface and basically an active-message call.  Since passive target
requires mpid-rhcv, we put it in as a building block.}

\subsubsection{Efficient Collective Algorithms}
\begin{enumerate}
\item Store and forward --- Since the message may need to be placed in
special memory, separating out the buffer used for the final receive
(possibly after unpacking into a buffer described with non-contiguous
data type) and the memory from which the message could be forwarded is
an important goal.  Further, store and
forward operations often should be \emph{pipelined}; that is, sent in
chunks, where each chunk is forwarded it as it is received.
Just to make things more complex, in collective algorithms, the data
received is often processed (e.g., for reduce) and/or forwarded to
multiple destinations.  These needs, taken together, encourage the
definition of store and forward ``building block'' routines; the \code{Stream}
module contains these routines.

\item Scatter/Gather --- A number of algorithms rely on dividing the
message up into separate pieces, based on viewing the message as a
contiguous array of bytes, and (in some cases) gathering the pieces
up.  For example, a simple broadcast can be written as a scatter step
followed by an Allgather step.  To write these for arbitrary (i.e.,
noncontiguous) datatypes requires the ability to divide the message up
independent of the datatype.  

\item Blocking --- An advantage of the (non File) collective
operations is that they are blocking.  This allows the code
implementing the collective operation to remain in control; in
particular, it can wait for an operation to complete and then perform
the next step.  This feature influenced the design of the
\code{Stream} module.
\end{enumerate}

\subsection{Multi-method Communication}
An important implementation of the this ADI is the model multi-method
implementation, based on separate message queues for each method.
This device illustrates a more complex use of the ADI interface.  It
implements not only the MPID CORE but most of the point-to-point
routines as well, along with the collective support routines.  The
generic modules are used for the rest of the ADI implementation.

To make it possible to implement this kind of multi-method device, the
ADI is careful with how MPI requests are handled.  It also defined a
very high-level ADI interface (e.g., \code{MPID_Isend}) that gives the
device the flexibility to determine the appropriate method and allows
the method to determine the appropriate protocol for delivering a message.

\subsection{Contrast with ADI-1 and ADI-2}
\label{sec-historical}
\textbf{This section will describe differences in concept and goals}

In ADI-1 and ADI-2, non-contiguous datatypes were handled by first
allocating a buffer large enough to hold the \emph{entire} message and
then either packing the message into that buffer (for a send) or
unpacking it after it was delivered (for a receive).  This was a
reasonable expedient when the original MPICH implementation was done,
but is not acceptable in a mature package.

\texttt{MPID_CORE} in ADI-3 corresponds to the `channel' device in ADI-2 in
the sense that it is a small set of routines, which, when combined with the
generic implementations of the other modules, gives a complete ADI
implementation.  

The ADI-2 channel interface was designed to fit the high-performance system
software of the day, which was proprietary message-passing libraries on
distributed memory parallel computers.  With the success of MPI, these
proprietary libraries have vanished, and advances in interconnect technology
have changed the API used to access high-performance interprocess
communication.  ADI-3 adapts to these changes.

\section{Things Left to do}
What relationship does the ADI interface to dynamic processes 
have to the BNR interface?  Should there be a connection between BNR groups
and MPID groups?


\code{MPID_Join} involves sockets, to we might make it part of the
utility module.  But what routines from \code{MPID_Core} must it call
to connect up the processes?

%Error reporting.  The ADI needs to know how to create MPI error codes.

%\section{ADI-3 Routines}
%\input adi3func.tex

%\section{ADI-3 Datastructures}
%\input adi3data.tex


\section{Integrating a Device into the MPICH build tree}
Still to do.  This section needs to cover:
\begin{enumerate}
\item Directory structure.  Where will mpich look for a new device
\item Local configure/setup script.  How the top-level mpich configure invokes
  the device-specific setup scripts
\item mpiexec.  How mpich creates the correct mpiexec
\item Installation.  How mpich gets the proper device-specific files
  installed; e.g., the mpd for the mpd device.
\item Device-specific documentation, such as environment variables and
  command-line arguments used only by a particular device.
\item Testing codes for device-specific functions
\end{enumerate}

% Add manual entries to the table of contents
\mancontentstrue

\section{Overview}
\input Overview.tex
\input OpaqOverview.tex

\subsection{Data Structures and Constants}
\input DSOverview.tex
\input Constants.tex
\input DyOverview.tex

\section{Summary of MPID Routines by Module}

\subsection{MPID Core}
\begin{verbatim}
    MPID_Abort
    MPID_Finalize
    MPID_Flags_testsome
    MPID_Flags_waitsome
    MPID_Open_port
    MPID_Put
    MPID_Rhcv
    MPID_Thread_init
\end{verbatim}
%    MPID_Hid_Cancel (handler)
%    MPID_Hid_Request_to_send (handler)

\subsection{Dynamic}
\begin{verbatim}
    MPID_Close_port
    MPID_Comm_accept
    MPID_Comm_connect
    MPID_Comm_disconnect
    MPID_Comm_spawn_multiple
\end{verbatim}

\subsection{Handlers}
%\begin{verbatim}
    Need enumeration of non-core handlers for \code{MPID_Rhcv}.  Perhaps these 
    belong in various modules.
%\end{verbatim}

\subsection{Attributes}
\begin{verbatim}
    MPID_Attr_delete
    MPID_Attr_find
    MPID_Attr_list_walk
    MPID_Attr_predefined
    MPID_Comm_attr_notify
\end{verbatim}
%   MPID_Lang_t


\subsection{Datatypes}
\begin{verbatim}
    MPID_Datatype_free
    MPID_Datatype_incr
    MPID_Datatype_new
    MPID_Pack_size
    MPID_Pack
    MPID_Unpack
    MPID_Segment_free
    MPID_Segment_init_pack
    MPID_Segment_init_unpack
    MPID_Segment_pack
    MPID_Segment_unpack
\end{verbatim}
%    MPID_Datatype
%    MPID_Segment

\subsection{Groups}
\begin{verbatim}
    MPID_Group_free
    MPID_Group_incr
    MPID_Group_new
\end{verbatim}
%    MPID_Group
%    MPID_Lpidmask

\subsection{Communicators}
\begin{verbatim}
    MPID_Comm_create
    MPID_Comm_free
    MPID_Comm_incr
    MPID_Comm_thread_lock
    MPID_Comm_thread_unlock
\end{verbatim}
%    MPID_Comm

\subsection{Requests}
\begin{verbatim}
    MPID_Request_cancel
    MPID_Request_FOA
    MPID_Request_free
    MPID_Request_iprobe
    MPID_Request_new
    MPID_Request_ready
\end{verbatim}
% MPID_Request

\subsection{Communication}
\begin{verbatim}
    MPID_Flags_testall
    MPID_Flags_waitall
    MPID_Get
    MPID_Isend
    etc.
    MPID_Memory_register
    MPID_Memory_unregister
    MPID_Rhc
    MPID_tBsend
\end{verbatim}

\subsection{Streams}
\begin{verbatim}
    MPID_Stream_iforward
    MPID_Stream_irecv
    MPID_Stream_isend
    MPID_Stream_wait
\end{verbatim}
%MPID_Stream

\subsection{Window Objects}
\begin{verbatim}
    MPID_Mem_alloc
    MPID_Mem_free
\end{verbatim}
%    MPID_Win

\subsection{Timers}
\begin{verbatim}
    MPID_Gwtick
    MPID_Gwtime_init
    MPID_Gwtime_diff
    MPID_Wtime_init
    MPID_Wtick
    MPID_Wtime_diff
    MPID_Wtime
\end{verbatim}

\subsection{Topology}
\begin{verbatim}
    MPID_Topo_cluster_info
\end{verbatim}

\subsection{Utility}
\begin{verbatim}
    MPID_Calloc
    MPID_Free
    MPID_Malloc
    MPID_Memcpy
    MPID_Strdup
\end{verbatim}

\subsection{Environment}
\begin{verbatim}
    MPID_MAX_THREAD_LEVEL
    MPID_THREAD_LEVEL
\end{verbatim}

\subsection{Error Reporting}
\begin{verbatim}
    MPID_Err_create_code
    MPID_Err_get_string
    MPID_Err_set_msg
    MPID_Err_add_class
    MPID_Err_add_code
    MPID_Err_delete_code
    MPID_Err_delete_class
\end{verbatim}

\section{MPID Core}
\input MPID_CORE-list.tex
\input Handlers.tex

\section{mpiexec}
\textbf{Need some discussion of mpiexec}

\section{Attributes}
\input AttrOverview.tex
\input KyOverview.tex
\input InfoOverview.tex
\input Attribute-list.tex

\section{Datatypes}
\input Datatype-list.tex
\input SGOverview.tex
\input Segment-list.tex

\section{Groups}
\input LocalPID.tex
\input Group-list.tex

\section{Communicators}
\input Communicator-list.tex

\section{Dynamic}
\input Dynamic-list.tex

\section{Requests}
\input Request-list.tex

\section{Communication}
\input CMOverview.tex
\input Communication-list.tex

\section{Streams}
\input StmOverview.tex
\input Stream-list.tex

\section{Window Objects}
\input Win-list.tex

\section{Timers}
\input Timer-list.tex

\section{Topology}
\input TopoOverview.tex
\input Topology-list.tex

\section{Utility}
\input Memory.tex
\input Utility-list.tex 

\section{Environment}
\input Environment-list.tex

\section{Error Reporting}
MPI allows separate error codes and classes.  An error \emph{class} is
a predefined value that roughly corresponds to a Unix error code
(e.g., \code{E_NOMEM}).  From a user's perspective, the major problem
with a simple error code (class in MPI terms) is that it is a
\emph{generic} message that gives no information about the particular
cause of the error.  For example, the Unix error code \code{E_NOMEM}
only tells the user that no memory is available.  The user might
prefer a message that included the amount of memory requested, such as 
\begin{verbatim}
Requested memory unavailable (requested 104732811 bytes 
in file getmem.c, line 137).
\end{verbatim}
The MPI error code provides a way to provide this kind of detailed
information.  An MPI error code may be though of as an
augmented error class that allows the MPI library to provide more
detailed information about an error.  MPICH uses error codes for this
purpose.  

In MPICH, an error code has three components:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
instance id&base code&base class\\
\hline
\end{tabular}
\end{center}
where the fields are
\begin{description}
\item[\texttt{base class}]The MPI error class, from the defined classes
\item[\texttt{base code}]Specifies more specific error message than
the \code{base class} but which contains no instance-specific data
\item[\texttt{instance id}]Used to indicate an instance-specific message
\end{description}

Values of zero for the \code{base code} and \code{instance id} are
always valid; in that case the error code is simply the error class.

The values encoded in \code{instance id} are defined by
\code{MPID_Err_create_code}; the routine \code{MPID_Err_get_string}
understands the \code{instance id} field.  One possible implementation
of this is described in (technical note not yet written, but described
in ALICE brown bag talk and Coding Standards document), and is
included with the MPICH implementation.

\paragraph
Messages are \code{char *} instead of \code{wchar_t *} because (a)
strings in C are \code{char *} and error strings in MPI are \code{char
*}.  However, we'd like to support Unicode messages.  We may just
return \code{char *} always, and allow the user to interpret the
message as either \code{char} or \code{wchar_t}.

\input Error-list.tex

\section{Extensions}
\input Extension-list.tex

\openin\testfile{None-list.tex}
\ifeof\testfile\else
\section{Miscellaneous}
\input None-list.tex
\fi
\closein\testfile

\end{document}
